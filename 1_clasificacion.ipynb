{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6YTaQq9dCh0E"
   },
   "source": [
    "# Clasificación de palabras (por género de nombre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49
    },
    "id": "5co_TuOhC4ze",
    "outputId": "6ed198ee-9cb9-48b9-ab74-db9655585c0e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package names to /home/oem/nltk_data...\n",
      "[nltk_data]   Package names is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk, random\n",
    "nltk.download('names')\n",
    "from nltk.corpus import names "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ijhsE2PBFYxm"
   },
   "source": [
    "**Función básica de extracción de atributos**\n",
    "\n",
    "Creamos una función donde nos devuelve unicamente la última letra de cada palabra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "b0kKV62lCZ55"
   },
   "outputs": [],
   "source": [
    "# definición de atributos relevantes\n",
    "def atributos(palabra):\n",
    "    return {'Ultima letra': palabra[-1]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ijhsE2PBFYxm"
   },
   "source": [
    "Unimos la lista de nombres **masculinos** y **femeninos** en una lista de tuplas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7944"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagset = [(name, 'male') for name in names.words('male.txt')] + [(name, 'female') for name in names.words('female.txt')]\n",
    "len(tagset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ijhsE2PBFYxm"
   },
   "source": [
    "Hacemos que la lista sea distribuida aleatoriamente para evitar el sesgo, ya que la lista de nombres masculinos queda primero que la lista de nombres femeninos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 181
    },
    "id": "IjfK5ZKwDL__",
    "outputId": "fef1000d-e474-43f0-986d-10b721946e59"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Lust', 'female'),\n",
       " ('Melisenda', 'female'),\n",
       " ('Donny', 'female'),\n",
       " ('Jewelle', 'female'),\n",
       " ('Filbert', 'male'),\n",
       " ('Monte', 'male'),\n",
       " ('Norwood', 'male'),\n",
       " ('Heidie', 'female'),\n",
       " ('Ximenez', 'male'),\n",
       " ('Joelle', 'female')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.shuffle(tagset)\n",
    "tagset[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ijhsE2PBFYxm"
   },
   "source": [
    "Creo una segunda lista de atributos, ya que nuestro modelo NO lee los nombres, sino los atributos de los nombres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 181
    },
    "id": "jZcAN-dmCrok",
    "outputId": "b114852f-8e71-4121-fda3-21bb731353b4"
   },
   "outputs": [],
   "source": [
    "fset1 = [(atributos(n), g) for (n, g) in tagset]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ijhsE2PBFYxm"
   },
   "source": [
    "Divido el dataset en los conjuntos de entrenamiento y pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "QzK97C8BDmHR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5944\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "train1, test1 = fset1[2000:], fset1[:2000]\n",
    "print(len(train1))\n",
    "print(len(test1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qQPv0tW4Fd2G"
   },
   "source": [
    "**Modelo de clasificación Naive Bayes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "37jueg4nDQFs"
   },
   "outputs": [],
   "source": [
    "# entrenamiento del modelo NaiveBayes\n",
    "classifier = nltk.NaiveBayesClassifier.train(train1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BAWfUSHrEj3q"
   },
   "source": [
    " **Verificación de algunas predicciones**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "Mr8ytm8SEEZk",
    "outputId": "cf62ff8a-2722-4331-bf70-66aafff1d9e8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'female'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify(atributos('amanda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "c0GG1Y1_EPaO",
    "outputId": "6f286792-7845-44f8-b22b-1cf6815036a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'male'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify(atributos('peter'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XSUK14XhEqLL"
   },
   "source": [
    "**Performance del modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 32
    },
    "id": "p5S9qeCgsJSg",
    "outputId": "6339e65d-d66e-4c96-9053-ea70d0abdea7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7668236877523553\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier, train1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 32
    },
    "id": "lenwC5agEdvT",
    "outputId": "1ceb5e52-4db6-4c5f-c714-dbf72f90e652"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.747\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier, test1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aSNI7OFxGib0"
   },
   "source": [
    "**Mejores atributos**\n",
    "\n",
    "Los atributos se almacenan en un diccionario. Creo una función de atributos completamente personalizada (Hay que recordar que no hay un protocolo establecido para definir atributos).\n",
    "\n",
    "Para este caso:\n",
    "* Atributo 1: La primera letra de la palabra\n",
    "* Atributo 2: La última letra de la palabra\n",
    "* Atributo 3: Cuantas veces aparece una letra del alfabeto en la palabra\n",
    "* Atributo 4: Si el alfabeto tiene o no tiene una letra del alfabeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "k5uaIAdDGlq8"
   },
   "outputs": [],
   "source": [
    "def mas_atributos(nombre):\n",
    "    atributos = {}\n",
    "    atributos[\"primera_letra\"] = nombre[0].lower()\n",
    "    atributos[\"ultima_letra\"] = nombre[-1].lower()\n",
    "    for letra in 'abcdefghijklmnopqrstuvwxyz':\n",
    "        atributos[\"count({})\".format(letra)] = nombre.lower().count(letra)\n",
    "        atributos[\"has({})\".format(letra)] = (letra in nombre.lower())\n",
    "    return atributos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "6-gJIxKcHKvI"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'primera_letra': 'j',\n",
       " 'ultima_letra': 'n',\n",
       " 'count(a)': 0,\n",
       " 'has(a)': False,\n",
       " 'count(b)': 0,\n",
       " 'has(b)': False,\n",
       " 'count(c)': 0,\n",
       " 'has(c)': False,\n",
       " 'count(d)': 0,\n",
       " 'has(d)': False,\n",
       " 'count(e)': 0,\n",
       " 'has(e)': False,\n",
       " 'count(f)': 0,\n",
       " 'has(f)': False,\n",
       " 'count(g)': 0,\n",
       " 'has(g)': False,\n",
       " 'count(h)': 1,\n",
       " 'has(h)': True,\n",
       " 'count(i)': 0,\n",
       " 'has(i)': False,\n",
       " 'count(j)': 1,\n",
       " 'has(j)': True,\n",
       " 'count(k)': 0,\n",
       " 'has(k)': False,\n",
       " 'count(l)': 0,\n",
       " 'has(l)': False,\n",
       " 'count(m)': 0,\n",
       " 'has(m)': False,\n",
       " 'count(n)': 1,\n",
       " 'has(n)': True,\n",
       " 'count(o)': 1,\n",
       " 'has(o)': True,\n",
       " 'count(p)': 0,\n",
       " 'has(p)': False,\n",
       " 'count(q)': 0,\n",
       " 'has(q)': False,\n",
       " 'count(r)': 0,\n",
       " 'has(r)': False,\n",
       " 'count(s)': 0,\n",
       " 'has(s)': False,\n",
       " 'count(t)': 0,\n",
       " 'has(t)': False,\n",
       " 'count(u)': 0,\n",
       " 'has(u)': False,\n",
       " 'count(v)': 0,\n",
       " 'has(v)': False,\n",
       " 'count(w)': 0,\n",
       " 'has(w)': False,\n",
       " 'count(x)': 0,\n",
       " 'has(x)': False,\n",
       " 'count(y)': 0,\n",
       " 'has(y)': False,\n",
       " 'count(z)': 0,\n",
       " 'has(z)': False}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mas_atributos('jhon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "FBu25HHgHQtK"
   },
   "outputs": [],
   "source": [
    "fset2 = [(mas_atributos(n), g) for (n, g) in tagset]\n",
    "train2, test2 = fset2[2000:], fset2[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier2 = nltk.NaiveBayesClassifier.train(train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7823014804845222\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier2, train2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 32
    },
    "id": "8hWR9hOzHlNe",
    "outputId": "97d5f514-dfd5-474a-8755-4127a7bcb8dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.766\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier2, test2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rT7mmVnvFAcm"
   },
   "source": [
    "### Ejercicio de práctica\n",
    "\n",
    "**Objetivo:** Construye un classificador de nombres en español usando el siguiente dataset: \n",
    "https://github.com/jvalhondo/spanish-names-surnames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NphJqahkFnjO"
   },
   "source": [
    "1. **Preparación de los datos**: con un `git clone` puedes traer el dataset indicado a tu directorio en Colab, luego asegurate de darle el formato adecuado a los datos y sus features para que tenga la misma estructura del ejemplo anterior con el dataset `names` de nombres en ingles. \n",
    "\n",
    "* **Piensa y analiza**: ¿los features en ingles aplican de la misma manera para los nombres en español?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "OhbOT6_zFGHM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: la ruta de destino 'spanish-names-surnames' ya existe y no es un directorio vacío.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/jvalhondo/spanish-names-surnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atributos_esp(nombre):\n",
    "    atributos = {}\n",
    "    atributos[\"primera_letra\"] = nombre[0].lower()\n",
    "    atributos[\"ultima_letra\"] = nombre[-1].lower() #Ultima letra\n",
    "    #atributos[\"ultimas_cinco_letras\"] = nombre[-5:].lower() #ultimas 5 letras\n",
    "    atributos[\"palabras\"] = len(nombre.split(\" \")) #Cuantas palabras tiene el nombre\n",
    "    for i, palabra in enumerate(nombre.split(\" \")):\n",
    "        atributos[\"primera_letra({})\".format(i)] = palabra[0].lower()\n",
    "        atributos[\"ultima_letra({})\".format(i)] = palabra[-1].lower()\n",
    "    return atributos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "tag_men = np.genfromtxt('spanish-names-surnames/male_names.csv', skip_header=1, delimiter=',', dtype=('U20','i8','f8'))\n",
    "tag_women = np.genfromtxt('spanish-names-surnames/female_names.csv', skip_header=1, delimiter=',', dtype=('U20','i8','f8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49340"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagsetE = [(name[0], 'male') for name in tag_men] + [(name[0], 'female') for name in tag_women]\n",
    "len(tagsetE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NADIUSKA', 'female'),\n",
       " ('DJIBY', 'male'),\n",
       " ('POMPEYA', 'female'),\n",
       " ('MARYAMA', 'female'),\n",
       " ('ELICINIA', 'female'),\n",
       " ('JUANA MAGDALENA', 'female'),\n",
       " ('MANUEL CEFERINO', 'male'),\n",
       " ('DENISA ANA MARIA', 'female'),\n",
       " ('MARTIRIO', 'female'),\n",
       " ('GRACIELA ROSA', 'female'),\n",
       " ('YUHAN', 'male'),\n",
       " ('HONGFEN', 'female'),\n",
       " ('ERIKA JULIETH', 'female'),\n",
       " ('RICARDO GABRIEL', 'male'),\n",
       " ('ROSA ERLINDA', 'female'),\n",
       " ('PAOLA CAROLINA', 'female'),\n",
       " ('VICTOR FELIPE', 'male'),\n",
       " ('MARIA IDAIRA', 'female'),\n",
       " ('CANDELARIA COVADONGA', 'female'),\n",
       " ('RAUL JULIAN', 'male'),\n",
       " ('DUMITRU VASILE', 'male'),\n",
       " ('USOA', 'female'),\n",
       " ('PLAMEN IVANOV', 'male'),\n",
       " ('CONRADA', 'female'),\n",
       " ('ELVIRA JOSEFA', 'female'),\n",
       " ('RANA', 'female'),\n",
       " ('PAUL IOAN', 'male'),\n",
       " ('LUISA', 'female'),\n",
       " ('MARIA INOCENTA', 'female'),\n",
       " ('MIRIAN DOLORES', 'female'),\n",
       " ('MARIA DAVINIA', 'female'),\n",
       " ('SERGE', 'male'),\n",
       " ('JOSHUA JAMES', 'male'),\n",
       " ('NUNO FELIPE', 'male'),\n",
       " ('EDGAR SANTIAGO', 'male'),\n",
       " ('KATRIEN', 'female'),\n",
       " ('RAUL EDUARDO', 'male'),\n",
       " ('JOB', 'male'),\n",
       " ('LEONOR TERESA', 'female'),\n",
       " ('LUIZ GUSTAVO', 'male'),\n",
       " ('MARIA JOSEFA', 'female'),\n",
       " ('AIKO', 'female'),\n",
       " ('GOIO', 'male'),\n",
       " ('ZIQI', 'female'),\n",
       " ('MARIA MIREYA', 'female'),\n",
       " ('VICENTE SALVADOR', 'male'),\n",
       " ('RAMON DANIEL', 'male'),\n",
       " ('NICOLASA MARIA', 'female'),\n",
       " ('COLIN GEORGE', 'male'),\n",
       " ('CATHAYSA PINO', 'female'),\n",
       " ('GALO JAVIER', 'male'),\n",
       " ('CHAIMAA', 'female'),\n",
       " ('BENITA MARIA', 'female'),\n",
       " ('GLADYS YOLANDA', 'female'),\n",
       " ('CONSUELO ROSARIO', 'female'),\n",
       " ('CORALI', 'female'),\n",
       " ('DENIS MANUEL', 'male'),\n",
       " ('YANELIS', 'female'),\n",
       " ('PABLO RAFAEL', 'male'),\n",
       " ('GEMMA TERESA', 'female'),\n",
       " ('ANDRES JAIME', 'male'),\n",
       " ('TARIEL', 'male'),\n",
       " ('SOUHILA', 'female'),\n",
       " ('OLIVIA TERESA', 'female'),\n",
       " ('CARMEN ALICIA', 'female'),\n",
       " ('BELA', 'female'),\n",
       " ('LUISA CAROLINA', 'female'),\n",
       " ('ADRIANA PATRICIA', 'female'),\n",
       " ('LUIS SANTOS', 'male'),\n",
       " ('MIKA', 'male'),\n",
       " ('WILSON ROLANDO', 'male'),\n",
       " ('JANE', 'female'),\n",
       " ('KEVIN ANDRES', 'male'),\n",
       " ('ONINTZE', 'female'),\n",
       " ('MINERVINA', 'female'),\n",
       " ('ANA MILENA', 'female'),\n",
       " ('EUSEBIO CARLOS', 'male'),\n",
       " ('CAROLINA VANESA', 'female'),\n",
       " ('AMY ELIZABETH', 'female'),\n",
       " ('PETKO', 'male'),\n",
       " ('MONIKA BARBARA', 'female'),\n",
       " ('LAZARO JAVIER', 'male'),\n",
       " ('ESTHER RUTH', 'female'),\n",
       " ('SIMONA ANA', 'female'),\n",
       " ('UWE', 'male'),\n",
       " ('LILIAN PATRICIA', 'female'),\n",
       " ('ESCLAVITUD', 'female'),\n",
       " ('ALESANDRO', 'male'),\n",
       " ('DAMIAN GABRIEL', 'male'),\n",
       " ('ANGEL LEOPOLDO', 'male'),\n",
       " ('JOSEFA SOCORRO', 'female'),\n",
       " ('JOSE HIPOLITO', 'male'),\n",
       " ('MANUEL ROGELIO', 'male'),\n",
       " ('PERPETUA', 'female'),\n",
       " ('SHIYONG', 'male'),\n",
       " ('SOFIA MARIE', 'female'),\n",
       " ('NICOLAS EMANUEL', 'male'),\n",
       " ('ALISON JANE', 'female'),\n",
       " ('MAYSA', 'female'),\n",
       " ('FANKA', 'female'),\n",
       " ('REMEDIOS DOLORES', 'female'),\n",
       " ('ALBERTO RICARDO', 'male'),\n",
       " ('DENNIS', 'female'),\n",
       " ('MARISE', 'female'),\n",
       " ('YOLANDA ALICIA', 'female'),\n",
       " ('SCARLETT', 'female'),\n",
       " ('YONGQIANG', 'male'),\n",
       " ('ARTURO FRANCISCO', 'male'),\n",
       " ('MARIA SERAFINA', 'female'),\n",
       " ('DIEGO PATRICIO', 'male'),\n",
       " ('JOHN KEVIN', 'male'),\n",
       " ('MANUEL VENANCIO', 'male'),\n",
       " ('SAMARA MARIA', 'female'),\n",
       " ('ANTONIO LEOPOLDO', 'male'),\n",
       " ('NAZARET', 'male'),\n",
       " ('SALAMA', 'female'),\n",
       " ('CHRISTIAN ALEJANDRO', 'male'),\n",
       " ('NIEVES LUISA', 'female'),\n",
       " ('ILDEFONSA', 'female'),\n",
       " ('BANDIOUGOU', 'male'),\n",
       " ('JAVIER ANTONIO', 'male'),\n",
       " ('ALMIRO', 'male'),\n",
       " ('GAYE', 'male'),\n",
       " ('MARIA MARIOLA', 'female'),\n",
       " ('MIREN AMAIUR', 'female'),\n",
       " ('XUELING', 'female'),\n",
       " ('GILBERTO ANTONIO', 'male'),\n",
       " ('SUMMER', 'female'),\n",
       " ('SAMER', 'male'),\n",
       " ('BERNARDO JAVIER', 'male'),\n",
       " ('DILYANA', 'female'),\n",
       " ('JORGE HERNAN', 'male'),\n",
       " ('KARLOTA', 'female'),\n",
       " ('MARTHA ELIZABETH', 'female'),\n",
       " ('FENG', 'male'),\n",
       " ('MARIANA LAURA', 'female'),\n",
       " ('EVENCIO', 'male'),\n",
       " ('IRINA IOANA', 'female'),\n",
       " ('MUHAMMAD ALI', 'male'),\n",
       " ('ESTHER LUISA', 'female'),\n",
       " ('EDGAR GEOVANNY', 'male'),\n",
       " ('LUISA CECILIA', 'female'),\n",
       " ('TIMOTHEE', 'male'),\n",
       " ('FRANCISCO FULGENCIO', 'male'),\n",
       " ('VLADISLAVA', 'female'),\n",
       " ('VICTOR JAVIER', 'male'),\n",
       " ('ERIC ADRIAN', 'male'),\n",
       " ('KELLY VANESSA', 'female'),\n",
       " ('HORACIA', 'female'),\n",
       " ('KARINA ALEJANDRA', 'female'),\n",
       " ('SUJUAN', 'female'),\n",
       " ('ALEXANDRA CATALINA', 'female'),\n",
       " ('ZHENGFEN', 'female'),\n",
       " ('FULGENCIO ANTONIO', 'male'),\n",
       " ('MAREIKE', 'female'),\n",
       " ('SEGUNDO EFRAIN', 'male'),\n",
       " ('MOHAMED KHALIL', 'male'),\n",
       " ('JEAN ELIZABETH', 'female'),\n",
       " ('YUEE', 'female'),\n",
       " ('ALBERTO LUIS', 'male'),\n",
       " ('MARINA ELENA', 'female'),\n",
       " ('MOHAMED AIMAN', 'male'),\n",
       " ('ELISA ESTHER', 'female'),\n",
       " ('ELOY ANTONIO', 'male'),\n",
       " ('RAFAEL LEOPOLDO', 'male'),\n",
       " ('MOHAMED ANUAR', 'male'),\n",
       " ('HILLARY', 'female'),\n",
       " ('MIRIAN RAQUEL', 'female'),\n",
       " ('JEAN MARCEL', 'male'),\n",
       " ('LLUIS FERRAN', 'male'),\n",
       " ('ACOYDAN', 'male'),\n",
       " ('YUCHENG', 'male'),\n",
       " ('MARIA COSMINA', 'female'),\n",
       " ('BENTCHEY', 'male'),\n",
       " ('NAEVIA', 'female'),\n",
       " ('GILSON', 'male'),\n",
       " ('ANTONIA OLGA', 'female'),\n",
       " ('IVANKA GEORGIEVA', 'female'),\n",
       " ('ANTONIA ROSA', 'female'),\n",
       " ('BLANCA LIBIA', 'female'),\n",
       " ('STEFAN MARIUS', 'male'),\n",
       " ('BETZAIDA', 'female'),\n",
       " ('AUGUST', 'male'),\n",
       " ('ZHENZHEN', 'female'),\n",
       " ('JAIR', 'male'),\n",
       " ('ABELIO', 'male'),\n",
       " ('FRANCISCO GUSTAVO', 'male'),\n",
       " ('SILVERI', 'male'),\n",
       " ('VALERIA SOFIA', 'female'),\n",
       " ('RODRIGO JESUS', 'male'),\n",
       " ('ADRIANA PAOLA', 'female'),\n",
       " ('VIRGINIA BEATRIZ', 'female'),\n",
       " ('NEREA PILAR', 'female'),\n",
       " ('YOLANDA SUSANA', 'female'),\n",
       " ('SOFIA ROCIO', 'female'),\n",
       " ('NDEYE COUMBA', 'female'),\n",
       " ('BLANCA GLORIA', 'female'),\n",
       " ('EDINSON', 'male'),\n",
       " ('MIREN OLATZ', 'female'),\n",
       " ('DOMINGO GREGORIO', 'male'),\n",
       " ('ANTOINE', 'male'),\n",
       " ('JORGE ANTONIO', 'male'),\n",
       " ('CATALINA ELIZABETH', 'female'),\n",
       " ('MUNAWAR', 'male'),\n",
       " ('VICENTA MARGARITA', 'female'),\n",
       " ('JAZAEL', 'male'),\n",
       " ('IZAN DAVID', 'male'),\n",
       " ('DICKSON', 'male'),\n",
       " ('LISBETH', 'female'),\n",
       " ('ANDREW ROBERT', 'male'),\n",
       " ('LARA PILAR', 'female'),\n",
       " ('GERD', 'male'),\n",
       " ('SOFIA ANGELES', 'female'),\n",
       " ('CATINCA', 'female'),\n",
       " ('CATALINA NICOLETA', 'female'),\n",
       " ('SHAIMAA', 'female'),\n",
       " ('MIHAI GEORGE', 'male'),\n",
       " ('MARIVIC', 'female'),\n",
       " ('ROSENDO', 'male'),\n",
       " ('BRITT MARIE', 'female'),\n",
       " ('PURIFICACION ISABEL', 'female'),\n",
       " ('ELISA ISABEL', 'female'),\n",
       " ('PASCUAL FERNANDO', 'male'),\n",
       " ('XULI', 'female'),\n",
       " ('ISIDRO ANGEL', 'male'),\n",
       " ('NEONILA', 'female'),\n",
       " ('IHARA', 'female'),\n",
       " ('CARMEN VALLE', 'female'),\n",
       " ('MIGUEL AITOR', 'male'),\n",
       " ('IVAN STEFANOV', 'male'),\n",
       " ('ANTONIO PEDRO', 'male'),\n",
       " ('MARCELO JORGE', 'male'),\n",
       " ('MUHAMMAD ZAHID', 'male'),\n",
       " ('JOSE DIMAS', 'male'),\n",
       " ('GAVINO', 'male'),\n",
       " ('GERAI', 'male'),\n",
       " ('FELIX AURELIO', 'male'),\n",
       " ('CHENJIE', 'male'),\n",
       " ('RUTH MARY', 'female'),\n",
       " ('ANITZ', 'female'),\n",
       " ('MARIA PILAR BEGOÑA', 'female'),\n",
       " ('GABRIELA LUCIA', 'female'),\n",
       " ('WEAM', 'female'),\n",
       " ('AURORA MARIA', 'female'),\n",
       " ('JULENE', 'female'),\n",
       " ('JERAY', 'male'),\n",
       " ('ADONINO', 'male'),\n",
       " ('ESTEBAN ANGEL', 'male'),\n",
       " ('MILLARAY', 'female'),\n",
       " ('EVA SOFIA', 'female'),\n",
       " ('MARIA IDOIA', 'female'),\n",
       " ('SHAKEEL', 'male'),\n",
       " ('MARCOS GABRIEL', 'male'),\n",
       " ('MANUEL CESAR', 'male'),\n",
       " ('ELISA MARIA', 'female'),\n",
       " ('JOSEPH WILLIAM', 'male'),\n",
       " ('DANIEL EZEQUIEL', 'male'),\n",
       " ('JACOBUS', 'male'),\n",
       " ('CHARLY', 'male'),\n",
       " ('HAGIE', 'male'),\n",
       " ('NAYDEN', 'male'),\n",
       " ('JAIME ADOLFO', 'male'),\n",
       " ('JORDI MANUEL', 'male'),\n",
       " ('RAMONA LUISA', 'female'),\n",
       " ('CHAFIA', 'female'),\n",
       " ('KAUSAR', 'female'),\n",
       " ('PABLO CRISTIAN', 'male'),\n",
       " ('YOLANDA ASUNCION', 'female'),\n",
       " ('ROSA JACQUELINE', 'female'),\n",
       " ('TARUN', 'male'),\n",
       " ('ANDREW PHILIP', 'male'),\n",
       " ('FRANCISCO SERAFIN', 'male'),\n",
       " ('XISCO', 'male'),\n",
       " ('ANNE LAURE', 'female'),\n",
       " ('RANJIT', 'male'),\n",
       " ('LILIAN ESTHER', 'female'),\n",
       " ('HUIMIN', 'female'),\n",
       " ('ENCARNACION JESUS', 'female'),\n",
       " ('PEDRO ISIDRO', 'male'),\n",
       " ('VANESSA ELIZABETH', 'female'),\n",
       " ('ARACELI JESUS', 'female'),\n",
       " ('MARTIN DANIEL', 'male'),\n",
       " ('MONIKA ANNA', 'female'),\n",
       " ('DUMITRU COSMIN', 'male'),\n",
       " ('JORGE CESAR', 'male'),\n",
       " ('JOAN ALFONS', 'male'),\n",
       " ('FRANCISCA ASCENSION', 'female'),\n",
       " ('FELIPE VICENTE', 'male'),\n",
       " ('ODILE', 'female'),\n",
       " ('JESUS JUAN', 'male'),\n",
       " ('GRACIELA CONCEPCION', 'female'),\n",
       " ('LUZ ANDREA', 'female'),\n",
       " ('KRZYSZTOF', 'male'),\n",
       " ('JOSE LUIS JESUS', 'male'),\n",
       " ('CLARA ASUNCION', 'female'),\n",
       " ('GURDIP', 'male'),\n",
       " ('NOUHAILA', 'female'),\n",
       " ('ANGEL BAUTISTA', 'male'),\n",
       " ('ROMAISSA', 'female'),\n",
       " ('MARIA LOIDA', 'female'),\n",
       " ('IORDAN', 'male'),\n",
       " ('ANDREEA PAULA', 'female'),\n",
       " ('MARCELI', 'male'),\n",
       " ('RENE ANTONIO', 'male'),\n",
       " ('COSMIN STEFAN', 'male'),\n",
       " ('MONICA GABRIELA', 'female'),\n",
       " ('SUIFEN', 'female'),\n",
       " ('JAVIER AUGUSTO', 'male'),\n",
       " ('LILIANA ROCIO', 'female'),\n",
       " ('DALMACIA', 'female'),\n",
       " ('CRISTINA ELISABETH', 'female'),\n",
       " ('BRAULIO', 'male'),\n",
       " ('DANIEL DOMINGO', 'male'),\n",
       " ('ANDREA PINO', 'female'),\n",
       " ('EMILIJA', 'female'),\n",
       " ('ROBERT CONSTANTIN', 'male'),\n",
       " ('IYA', 'female'),\n",
       " ('MANUELA MILAGROS', 'female'),\n",
       " ('TIBURCIA', 'female'),\n",
       " ('DENILSON', 'male'),\n",
       " ('JENIFER', 'female'),\n",
       " ('XANET', 'male'),\n",
       " ('LAURA FERNANDA', 'female'),\n",
       " ('ALBA YOLANDA', 'female'),\n",
       " ('YANGYANG', 'female'),\n",
       " ('MARIO RAMIRO', 'male'),\n",
       " ('RALUCA DIANA', 'female'),\n",
       " ('BOGDAN MARIUS', 'male'),\n",
       " ('SUNAMITA', 'female'),\n",
       " ('IGNACIO ANTONIO', 'male'),\n",
       " ('CHADYA', 'female'),\n",
       " ('JAEL', 'female'),\n",
       " ('GARA CARMEN', 'female'),\n",
       " ('LUCAS MATIAS', 'male'),\n",
       " ('HELIDA', 'female'),\n",
       " ('GABRIEL JULIAN', 'male'),\n",
       " ('JOSE MIGUEL', 'male'),\n",
       " ('MANUEL MODESTO', 'male'),\n",
       " ('SHEYLA MARIA', 'female'),\n",
       " ('FRUSINA', 'female'),\n",
       " ('YURIMA', 'female'),\n",
       " ('RODION', 'male'),\n",
       " ('ANDRES SANTOS', 'male'),\n",
       " ('BOGDAN CRISTIAN', 'male'),\n",
       " ('MARIA GORETI', 'female'),\n",
       " ('CARLOS GIOVANNI', 'male'),\n",
       " ('PEDRO CELESTINO', 'male'),\n",
       " ('AMALIA ROCIO', 'female'),\n",
       " ('ELY', 'female'),\n",
       " ('GUSTAVO', 'male'),\n",
       " ('ROXANA ADRIANA', 'female'),\n",
       " ('PAVLO', 'male'),\n",
       " ('HECTOR HERNAN', 'male'),\n",
       " ('SONJA', 'female'),\n",
       " ('SILVINO', 'male'),\n",
       " ('WALTER ALBERTO', 'male'),\n",
       " ('EVA ENCARNACION', 'female'),\n",
       " ('BRAULIO MANUEL', 'male'),\n",
       " ('DANIEL ALEXANDRE', 'male'),\n",
       " ('SOFIA NATALIA', 'female'),\n",
       " ('ALEJANDRO FABIAN', 'male'),\n",
       " ('NATALIA SOFIA', 'female'),\n",
       " ('HOUSSIN', 'male'),\n",
       " ('MARCELO HERNAN', 'male'),\n",
       " ('NEREA ISABEL', 'female'),\n",
       " ('JURI', 'male'),\n",
       " ('TIJAN', 'male'),\n",
       " ('ENOL', 'male'),\n",
       " ('VIKTOR', 'male'),\n",
       " ('DANIELA BELEN', 'female'),\n",
       " ('CATALINA IONELA', 'female'),\n",
       " ('GLADYS CONCEPCION', 'female'),\n",
       " ('CAROLINA SOLEDAD', 'female'),\n",
       " ('ESTEBAN MANUEL', 'male'),\n",
       " ('CARMEN SARA', 'female'),\n",
       " ('DORIS ISABEL', 'female'),\n",
       " ('ROBERT MARIAN', 'male'),\n",
       " ('KARIN', 'female'),\n",
       " ('ANICET', 'male'),\n",
       " ('AGNIESZKA MARTA', 'female'),\n",
       " ('CHARIFA', 'female'),\n",
       " ('HUGO ANDRES', 'male'),\n",
       " ('MARIA DILIA', 'female'),\n",
       " ('ALYA', 'female'),\n",
       " ('HECTOR TOMAS', 'male'),\n",
       " ('ANGEL SALVADOR', 'male'),\n",
       " ('KADDY', 'female'),\n",
       " ('CARMEN TEODORA', 'female'),\n",
       " ('FRAUKE', 'female'),\n",
       " ('MAURO EZEQUIEL', 'male'),\n",
       " ('JOAQUIN ERNESTO', 'male'),\n",
       " ('EDISON ENRIQUE', 'male'),\n",
       " ('XUJIE', 'male'),\n",
       " ('JUANA ANGELA', 'female'),\n",
       " ('ENAI', 'male'),\n",
       " ('ANGELICA CARMEN', 'female'),\n",
       " ('JOHN VICTOR', 'male'),\n",
       " ('HERENA', 'female'),\n",
       " ('JOSEP VICENÇ', 'male'),\n",
       " ('MARIA CARMEN DELIA', 'female'),\n",
       " ('JOSE VINICIO', 'male'),\n",
       " ('ALEXANDRU BOGDAN', 'male'),\n",
       " ('ANA OBDULIA', 'female'),\n",
       " ('ERIC FERNANDO', 'male'),\n",
       " ('DIEGO ALONSO', 'male'),\n",
       " ('GARTZEN', 'male'),\n",
       " ('JAHANGIR', 'male'),\n",
       " ('JAIRO ENRIQUE', 'male'),\n",
       " ('WIEBKE', 'female'),\n",
       " ('PAULA ROSA', 'female'),\n",
       " ('ERNESTO SALVADOR', 'male'),\n",
       " ('ANDREI MARIUS', 'male'),\n",
       " ('IRANZU', 'female'),\n",
       " ('ANTONIO MARCIAL', 'male'),\n",
       " ('GERALDINA', 'female'),\n",
       " ('NISHAN', 'male'),\n",
       " ('FINEAS', 'male'),\n",
       " ('DALIBOR', 'male'),\n",
       " ('HUGO ANGEL', 'male'),\n",
       " ('ANHARA', 'female'),\n",
       " ('ROBIN', 'female'),\n",
       " ('MARIA ARGELIA', 'female'),\n",
       " ('DYLAN GABRIEL', 'male'),\n",
       " ('ADRIANA SOLEDAD', 'female'),\n",
       " ('MOHAMED AKRAM', 'male'),\n",
       " ('LUCAS ANDRES', 'male'),\n",
       " ('BLANCA INES', 'female'),\n",
       " ('CANDELARIA', 'female'),\n",
       " ('MARYAN', 'male'),\n",
       " ('JHOAN MANUEL', 'male'),\n",
       " ('PATXI XABIER', 'male'),\n",
       " ('GUILLERMO JUAN', 'male'),\n",
       " ('HALYNA', 'female'),\n",
       " ('SARA ESTER', 'female'),\n",
       " ('NIKOLE', 'female'),\n",
       " ('NURIA CECILIA', 'female'),\n",
       " ('ADRIAN RAFAEL', 'male'),\n",
       " ('NASIMA', 'female'),\n",
       " ('MARIA XIOMARA', 'female'),\n",
       " ('VIRGINIA ROSA', 'female'),\n",
       " ('ANNE ELIZABETH', 'female'),\n",
       " ('MILLICENT', 'female'),\n",
       " ('MARIA CONSEJO', 'female'),\n",
       " ('FAMARA', 'female'),\n",
       " ('SHUKRI', 'male'),\n",
       " ('YOANIA', 'female'),\n",
       " ('ANGEL EFREN', 'male'),\n",
       " ('RAMAZAN', 'male'),\n",
       " ('NAUSICA', 'female'),\n",
       " ('MARIA DOLORES JOSEFA', 'female'),\n",
       " ('ESPERANZA MARIA', 'female'),\n",
       " ('BASILISA MARIA', 'female'),\n",
       " ('ALICIA EMILIA', 'female'),\n",
       " ('ARUME', 'female'),\n",
       " ('DOLORES BEATRIZ', 'female'),\n",
       " ('PAULA JANE', 'female'),\n",
       " ('XINGYU', 'male'),\n",
       " ('CARMEN EULALIA', 'female'),\n",
       " ('SONIA LUZ', 'female'),\n",
       " ('GHIZLAN', 'female'),\n",
       " ('JUAN AITOR', 'male'),\n",
       " ('DANIEL OSWALDO', 'male'),\n",
       " ('HAKIM', 'male'),\n",
       " ('ALFONSO LORENZO', 'male'),\n",
       " ('JUNWEI', 'male'),\n",
       " ('MARIA OLAS', 'female'),\n",
       " ('SALAH DIN', 'male'),\n",
       " ('THERESE', 'female'),\n",
       " ('CRISTOFOR', 'male'),\n",
       " ('ANGELES RAQUEL', 'female'),\n",
       " ('FILIBERTO', 'male'),\n",
       " ('CARMEN FELISA', 'female'),\n",
       " ('ADRIANA ESTHER', 'female'),\n",
       " ('TZVETELINA', 'female'),\n",
       " ('MADJID', 'male'),\n",
       " ('DASIO', 'male'),\n",
       " ('DARIUS DANIEL', 'male'),\n",
       " ('BEATRIU', 'female'),\n",
       " ('MARIA ODETTE', 'female'),\n",
       " ('LILIBETH', 'female'),\n",
       " ('OSCAR DANILO', 'male'),\n",
       " ('NELLI', 'female'),\n",
       " ('ANNA PAULA', 'female'),\n",
       " ('JOSE ROLANDO', 'male'),\n",
       " ('KATHERINE', 'female'),\n",
       " ('FLORENCIO JAVIER', 'male'),\n",
       " ('MARIA VICENTA', 'female'),\n",
       " ('ANDREW GEORGE', 'male'),\n",
       " ('REGLA', 'female'),\n",
       " ('WILLY', 'male'),\n",
       " ('JENNY CARMEN', 'female'),\n",
       " ('CESAR ALEXANDER', 'male'),\n",
       " ('EDILBERTA', 'female'),\n",
       " ('JOSE AGOSTINHO', 'male'),\n",
       " ('LUIS LORENZO', 'male'),\n",
       " ('PHILIP JOHN', 'male'),\n",
       " ('JESICA ALEJANDRA', 'female'),\n",
       " ('DANIEL VASILE', 'male'),\n",
       " ('ORLANDO JESUS', 'male'),\n",
       " ('MARIA CONTEMPLACION', 'female'),\n",
       " ('HIRA', 'female'),\n",
       " ('YIRA', 'female'),\n",
       " ('JULIA ROSARIO', 'female'),\n",
       " ('JOSE ALFONSO', 'male'),\n",
       " ('ANCA IONELA', 'female'),\n",
       " ('AYOZE', 'male'),\n",
       " ('JOAN ISAAC', 'male'),\n",
       " ('MARIUS VALENTIN', 'male'),\n",
       " ('SARA EMILIA', 'female'),\n",
       " ('BASEL', 'male'),\n",
       " ('HORTENCIA', 'female'),\n",
       " ('HUGO RAUL', 'male'),\n",
       " ('KIM', 'male'),\n",
       " ('RAUL SANTIAGO', 'male'),\n",
       " ('ALEXANDRU STEFAN', 'male'),\n",
       " ('VALENTIN JAVIER', 'male'),\n",
       " ('TERESA PURIFICACION', 'female'),\n",
       " ('RUBEN ORLANDO', 'male'),\n",
       " ('GIUSEPPA', 'female'),\n",
       " ('ELIOS', 'male'),\n",
       " ('NAJI', 'male'),\n",
       " ('JOSE NORBEY', 'male'),\n",
       " ('LORENA ANDREEA', 'female'),\n",
       " ('CARMEN COVADONGA', 'female'),\n",
       " ('GEOVANY', 'male'),\n",
       " ('JAROSLAW', 'male'),\n",
       " ('MARTA ASUNCION', 'female'),\n",
       " ('MARIANE', 'female'),\n",
       " ('INES CONSUELO', 'female'),\n",
       " ('LUIS HERNAN', 'male'),\n",
       " ('PEDRO EMILIO', 'male'),\n",
       " ('MARGARITA ALEJANDRA', 'female'),\n",
       " ('ESTEFANY', 'female'),\n",
       " ('JHON EDINSON', 'male'),\n",
       " ('ROALD', 'male'),\n",
       " ('TAISIA', 'female'),\n",
       " ('HERENIA', 'female'),\n",
       " ('IVANILDA', 'female'),\n",
       " ('KENNETH ALAN', 'male'),\n",
       " ('MIGUEL DARIO', 'male'),\n",
       " ('IGNACIO FEDERICO', 'male'),\n",
       " ('PABLO ANIBAL', 'male'),\n",
       " ('CARMELO ANTONIO', 'male'),\n",
       " ('DENIS ALEXANDRU', 'male'),\n",
       " ('LAYAL', 'female'),\n",
       " ('LUZ FANNY', 'female'),\n",
       " ('YASMINA', 'female'),\n",
       " ('CELIA PILAR', 'female'),\n",
       " ('JUAN BENEDICTO', 'male'),\n",
       " ('XIOMARA MARIA', 'female'),\n",
       " ('KIARA', 'female'),\n",
       " ('LUMINITA DANIELA', 'female'),\n",
       " ('SAINEY', 'male'),\n",
       " ('JOSE DIEGO', 'male'),\n",
       " ('SHUANGWEI', 'male'),\n",
       " ('MARY ANN', 'female'),\n",
       " ('JIAYUE', 'female'),\n",
       " ('AZUL', 'female'),\n",
       " ('MILAGROS JOSEFA', 'female'),\n",
       " ('FELIPE NERI', 'male'),\n",
       " ('GODSTIME', 'male'),\n",
       " ('IRMA GRACIELA', 'female'),\n",
       " ('LYES', 'male'),\n",
       " ('ROBERTH', 'male'),\n",
       " ('FIDEL ERNESTO', 'male'),\n",
       " ('NATANIEL', 'male'),\n",
       " ('ZORAYA', 'female'),\n",
       " ('SEGUNDO RODRIGO', 'male'),\n",
       " ('MARIANO SEBASTIAN', 'male'),\n",
       " ('MARIA ELISENDA', 'female'),\n",
       " ('CLOTILDE', 'female'),\n",
       " ('ANTHONY SEBASTIAN', 'male'),\n",
       " ('MARIA CAROLINA', 'female'),\n",
       " ('EDUARDO RUBEN', 'male'),\n",
       " ('CHADLI', 'male'),\n",
       " ('NOEL ANTONIO', 'male'),\n",
       " ('LUIS RAUL', 'male'),\n",
       " ('RUBEN FILIPE', 'male'),\n",
       " ('LORENZO MARIA', 'male'),\n",
       " ('BARTOLOMEA', 'female'),\n",
       " ('PONCIANO', 'male'),\n",
       " ('CALIN FLORIN', 'male'),\n",
       " ('FRANCISCA INMACULADA', 'female'),\n",
       " ('ANDREEA ALEXANDRA', 'female'),\n",
       " ('MARK ADRIAN', 'male'),\n",
       " ('HECTOR MARIO', 'male'),\n",
       " ('GEORGE CLAUDIU', 'male'),\n",
       " ('WALKIRIA', 'female'),\n",
       " ('MOUAAD', 'male'),\n",
       " ('JANET ANN', 'female'),\n",
       " ('MAURICIO IVAN', 'male'),\n",
       " ('MATIAS ALEXANDER', 'male'),\n",
       " ('VENELIN', 'male'),\n",
       " ('JIMENA SOLEDAD', 'female'),\n",
       " ('RUI FELIPE', 'male'),\n",
       " ('FIORDALIZA', 'female'),\n",
       " ('DEVIN', 'male'),\n",
       " ('MIRYAN', 'female'),\n",
       " ('JULIA GABRIELA', 'female'),\n",
       " ('NITA', 'male'),\n",
       " ('MARIA ANTONIA', 'female'),\n",
       " ('ISABEL LUCIA', 'female'),\n",
       " ('HUIYAN', 'female'),\n",
       " ('DORA LIGIA', 'female'),\n",
       " ('AYAX', 'male'),\n",
       " ('MAGALI ELIZABETH', 'female'),\n",
       " ('PURA', 'female'),\n",
       " ('GORAN', 'male'),\n",
       " ('BRIAN RICHARD', 'male'),\n",
       " ('KIMERA', 'female'),\n",
       " ('SORAYA ISABEL', 'female'),\n",
       " ('MADELEN', 'female'),\n",
       " ('BABOU', 'male'),\n",
       " ('JAVIER GUSTAVO', 'male'),\n",
       " ('RICARDINA', 'female'),\n",
       " ('IRAGARTZE', 'female'),\n",
       " ('JOSE MELITON', 'male'),\n",
       " ('JULIO MIGUEL', 'male'),\n",
       " ('JESUS JOSE MARIA', 'male'),\n",
       " ('VALDIR', 'male'),\n",
       " ('DONNA MARIE', 'female'),\n",
       " ('ISABEL CANDELARIA', 'female'),\n",
       " ('BRUNO MARTIN', 'male'),\n",
       " ('LUIS ARNALDO', 'male'),\n",
       " ('NELY', 'female'),\n",
       " ('LAURENTIU VALENTIN', 'male'),\n",
       " ('KARISHMA', 'female'),\n",
       " ('ILIUTA', 'male'),\n",
       " ('SAJA', 'female'),\n",
       " ('MARIA BALBINA', 'female'),\n",
       " ('SAMA', 'female'),\n",
       " ('LAURA INES', 'female'),\n",
       " ('TESLEM', 'female'),\n",
       " ('ENCARNACION MAR', 'female'),\n",
       " ('HARUTYUN', 'male'),\n",
       " ('DIONISIO RAFAEL', 'male'),\n",
       " ('INGRID JOHANA', 'female'),\n",
       " ('LYN', 'female'),\n",
       " ('GRACIA ISABEL', 'female'),\n",
       " ('MAIA', 'female'),\n",
       " ('PALOMA', 'female'),\n",
       " ('JOSE JULIO', 'male'),\n",
       " ('TAJAMAL', 'male'),\n",
       " ('SHUHUI', 'female'),\n",
       " ('TIGRAN', 'male'),\n",
       " ('EL KHAMSA', 'female'),\n",
       " ('JESUS', 'female'),\n",
       " ('XIUHUA', 'female'),\n",
       " ('SEBASTIAN STEFAN', 'male'),\n",
       " ('LUIS HERNANDO', 'male'),\n",
       " ('ZLATKA', 'female'),\n",
       " ('JOSU GOTZON', 'male'),\n",
       " ('ARNOLDO', 'male'),\n",
       " ('JUAN AARON', 'male'),\n",
       " ('MARIA VIÑAS', 'female'),\n",
       " ('IONUT SEBASTIAN', 'male'),\n",
       " ('MARIA TRANCITO', 'female'),\n",
       " ('ENRIQUE AMADOR', 'male'),\n",
       " ('SYED MUHAMMAD', 'male'),\n",
       " ('GEREMIAS', 'male'),\n",
       " ('CHRISTIAN GUILLERMO', 'male'),\n",
       " ('GUAYASEN', 'male'),\n",
       " ('TELESFORO', 'male'),\n",
       " ('ALICIA MATILDE', 'female'),\n",
       " ('IRMA SUSANA', 'female'),\n",
       " ('ENRIQUETA', 'female'),\n",
       " ('AROA', 'female'),\n",
       " ('JABBAR', 'male'),\n",
       " ('DABY', 'male'),\n",
       " ('SANTIAGO ISRAEL', 'male'),\n",
       " ('WILLIAM JAVIER', 'male'),\n",
       " ('ROBERT STEFAN', 'male'),\n",
       " ('CHRISTIAN FELIPE', 'male'),\n",
       " ('HRIPSIME', 'female'),\n",
       " ('ENIA', 'female'),\n",
       " ('RODRIGO HERNAN', 'male'),\n",
       " ('GUSTAVO FRANCISCO', 'male'),\n",
       " ('EXUPERANCIA', 'female'),\n",
       " ('COSTELA', 'female'),\n",
       " ('VICENTA ANTONIA', 'female'),\n",
       " ('LAURENTIU GABRIEL', 'male'),\n",
       " ('RENE JESUS', 'male'),\n",
       " ('MARIA BENICIA', 'female'),\n",
       " ('PIOTR MAREK', 'male'),\n",
       " ('JOAN ALBERT', 'male'),\n",
       " ('AGUSTIN MARIO', 'male'),\n",
       " ('NAISHA', 'female'),\n",
       " ('AIYING', 'female'),\n",
       " ('GONZALO GUILLERMO', 'male'),\n",
       " ('NATIVIDAD PINO', 'female'),\n",
       " ('JOEL LUIS', 'male'),\n",
       " ('CARLOS DIONISIO', 'male'),\n",
       " ('ALEKSANDAR DIMITROV', 'male'),\n",
       " ('FRANCISCA JOSEFA', 'female'),\n",
       " ('CILINIA', 'female'),\n",
       " ('AIXA', 'female'),\n",
       " ('STEPHANIE ANN', 'female'),\n",
       " ('KRASIMIR DIMITROV', 'male'),\n",
       " ('HANNELORE', 'female'),\n",
       " ('IGNACIO RAFAEL', 'male'),\n",
       " ('MARIA MONTESCLAROS', 'female'),\n",
       " ('REGIANE', 'female'),\n",
       " ('HARPREET', 'male'),\n",
       " ('ATIQ', 'male'),\n",
       " ('IKER DANIEL', 'male'),\n",
       " ('HANSEL', 'male'),\n",
       " ('MIRIAN ALEXANDRA', 'female'),\n",
       " ('KAMRAN', 'male'),\n",
       " ('GEORGICA', 'male'),\n",
       " ('NELIDA ESTER', 'female'),\n",
       " ('ABDESSADEK', 'male'),\n",
       " ('MARIANA FLORENTINA', 'female'),\n",
       " ('AMALIA BELEN', 'female'),\n",
       " ('YIQUN', 'male'),\n",
       " ('ANDER', 'male'),\n",
       " ('JOEL', 'male'),\n",
       " ('JHON MAURICIO', 'male'),\n",
       " ('ABBES', 'male'),\n",
       " ('MARIANA ANGELES', 'female'),\n",
       " ('FANIDA', 'female'),\n",
       " ('ELISABET CARMEN', 'female'),\n",
       " ('MARTA JOSEFINA', 'female'),\n",
       " ('CARLA VERONICA', 'female'),\n",
       " ('CRISTINA GUADALUPE', 'female'),\n",
       " ('YANMEI', 'female'),\n",
       " ('MARIYANA', 'female'),\n",
       " ('VICTORIANO JUAN', 'male'),\n",
       " ('FIDEL MANUEL', 'male'),\n",
       " ('BORIS ALEJANDRO', 'male'),\n",
       " ('NIKOLAY DIMITROV', 'male'),\n",
       " ('ALVARO MAURICIO', 'male'),\n",
       " ('NEHA', 'female'),\n",
       " ('ALBA CECILIA', 'female'),\n",
       " ('JUAN CRISOSTOMO', 'male'),\n",
       " ('TRINIDAD JOSEFA', 'female'),\n",
       " ('FRANCISCO ALEJO', 'male'),\n",
       " ('MARIE LUISE', 'female'),\n",
       " ('ERIC ANTONIO', 'male'),\n",
       " ('OANA ANDREEA', 'female'),\n",
       " ('MOISES RAFAEL', 'male'),\n",
       " ('LEONCIO JOSE', 'male'),\n",
       " ('NELSON RUBEN', 'male'),\n",
       " ('STEFANIA MIHAELA', 'female'),\n",
       " ('ROCIO ANGELES', 'female'),\n",
       " ('SANTIAGO BENITO', 'male'),\n",
       " ('EMILIANO MANUEL', 'male'),\n",
       " ('QASIM', 'male'),\n",
       " ('RQUIA', 'female'),\n",
       " ('FLORIN SEBASTIAN', 'male'),\n",
       " ('MARIA HILDA', 'female'),\n",
       " ('ZHIJIE', 'male'),\n",
       " ('BLANCA ALEXANDRA', 'female'),\n",
       " ('WAFAE', 'female'),\n",
       " ('ALHASSAN', 'male'),\n",
       " ('JARNAIL', 'male'),\n",
       " ('SAULE', 'female'),\n",
       " ('MARIA LOUISA', 'female'),\n",
       " ('CARMEN JOSE', 'female'),\n",
       " ('JOHN ANDER', 'male'),\n",
       " ('YULIAN', 'male'),\n",
       " ('LIANLIAN', 'female'),\n",
       " ('ABDELHAI', 'male'),\n",
       " ('RONNIE', 'male'),\n",
       " ('HAMED', 'male'),\n",
       " ('GEORGE MIHAITA', 'male'),\n",
       " ('EDUARDO ANGEL', 'male'),\n",
       " ('BERNARDETE', 'female'),\n",
       " ('ANDRES LEONARDO', 'male'),\n",
       " ('RICARDO ALBERTO', 'male'),\n",
       " ('LEIDY ANDREA', 'female'),\n",
       " ('MARTYNAS', 'male'),\n",
       " ('JOSE SIXTO', 'male'),\n",
       " ('ROMULUS', 'male'),\n",
       " ('PEDRO NOLASCO', 'male'),\n",
       " ('ERICK DAVID', 'male'),\n",
       " ('AIRTON', 'male'),\n",
       " ('EDWIN SANTIAGO', 'male'),\n",
       " ('ALINA MIHAELA', 'female'),\n",
       " ('JON MIREN', 'male'),\n",
       " ('ANGIE ALEXANDRA', 'female'),\n",
       " ('MAXIMILIANO ANTONIO', 'male'),\n",
       " ('ALBERTO ESTEBAN', 'male'),\n",
       " ('DANIEL BORJA', 'male'),\n",
       " ('HERNAN GONZALO', 'male'),\n",
       " ('MIHAI ALIN', 'male'),\n",
       " ('JUANA PAULINA', 'female'),\n",
       " ('NIRMAL', 'male'),\n",
       " ('AYTHAMI JOSE', 'male'),\n",
       " ('NIEVES MILAGROS', 'female'),\n",
       " ('ROBERTO JESUS', 'male'),\n",
       " ('MIRTA MARIA', 'female'),\n",
       " ('EÑAUT', 'male'),\n",
       " ('ENCARNACION DOLORES', 'female'),\n",
       " ('COSME DAMIAN', 'male'),\n",
       " ('LYDIA MARIA', 'female'),\n",
       " ('JULIAN ANTONIO', 'male'),\n",
       " ('PAULINE', 'female'),\n",
       " ('EMIL CRISTIAN', 'male'),\n",
       " ('JUSTINA MARIA', 'female'),\n",
       " ('MIRIAN ELIZABETH', 'female'),\n",
       " ('ALI', 'male'),\n",
       " ('MARIA PELIGROS', 'female'),\n",
       " ('MARIA POLONIA', 'female'),\n",
       " ('NAYRA ESTHER', 'female'),\n",
       " ('PEDRO JULIO', 'male'),\n",
       " ('MARIA BERTHA', 'female'),\n",
       " ('KAREM', 'female'),\n",
       " ('DICTINA', 'female'),\n",
       " ('SUNILDA', 'female'),\n",
       " ('SILVIA MABEL', 'female'),\n",
       " ('DANIELA MARCELA', 'female'),\n",
       " ('ASSMA', 'female'),\n",
       " ('MARTA LUCIA', 'female'),\n",
       " ('XUPING', 'male'),\n",
       " ('SUSAN KATHLEEN', 'female'),\n",
       " ('YAHAIRA', 'female'),\n",
       " ('PAULA VANESSA', 'female'),\n",
       " ('VICENTE ALBERTO', 'male'),\n",
       " ('ISABEL LUZ', 'female'),\n",
       " ('JOSEP EDUARD', 'male'),\n",
       " ('KAUAN', 'male'),\n",
       " ('CLEITON', 'male'),\n",
       " ('NICOLETA AURELIA', 'female'),\n",
       " ('RADOUAN', 'male'),\n",
       " ('JAVIER EUGENIO', 'male'),\n",
       " ('CHRISTIAN GIOVANNI', 'male'),\n",
       " ('FETTAH', 'male'),\n",
       " ('RANSES', 'male'),\n",
       " ('LUIS ANDREI', 'male'),\n",
       " ('ALICE MARIA', 'female'),\n",
       " ('BING', 'female'),\n",
       " ('MONICA ESTHER', 'female'),\n",
       " ('JESSIE', 'male'),\n",
       " ('ABELINA', 'female'),\n",
       " ('DARINKA', 'female'),\n",
       " ('CHAHD', 'female'),\n",
       " ('AMDY', 'male'),\n",
       " ('YAPCI', 'male'),\n",
       " ('ISABEL REGINA', 'female'),\n",
       " ('DARIUS IOAN', 'male'),\n",
       " ('MARGARITA CATALINA', 'female'),\n",
       " ('AZ EDDINE', 'male'),\n",
       " ('MATIAS RAFAEL', 'male'),\n",
       " ('SITAN', 'female'),\n",
       " ('CARLA CAROLINA', 'female'),\n",
       " ('SARA IOANA', 'female'),\n",
       " ('ELISANDRO', 'male'),\n",
       " ('JACINTO LUIS', 'male'),\n",
       " ('RAUL', 'male'),\n",
       " ('FRANKLIN RAFAEL', 'male'),\n",
       " ('IRIMIA', 'female'),\n",
       " ('CECILIA ROCIO', 'female'),\n",
       " ('LIMBERT', 'male'),\n",
       " ('AVELINA MARIA', 'female'),\n",
       " ('SAMIR', 'male'),\n",
       " ('ALEXANDRU DANIEL', 'male'),\n",
       " ('GARIKOITZ', 'male'),\n",
       " ('MARCOS GERMAN', 'male'),\n",
       " ('PRISCILO', 'male'),\n",
       " ('EMMA RAQUEL', 'female'),\n",
       " ('ROMY', 'female'),\n",
       " ('JOHANA MARIA', 'female'),\n",
       " ('LUCIA VALERIA', 'female'),\n",
       " ('MARIO ALEXANDRU', 'male'),\n",
       " ('AURORA JOSEFA', 'female'),\n",
       " ('ARIEL', 'female'),\n",
       " ('YOVANA', 'female'),\n",
       " ('ARACELI ROCIO', 'female'),\n",
       " ('ARFAN', 'male'),\n",
       " (\"M'BARKA\", 'female'),\n",
       " ('NENAD', 'male'),\n",
       " ('DANIELA PAULA', 'female'),\n",
       " ('TAMAS', 'male'),\n",
       " ('FRANCISCO NAUZET', 'male'),\n",
       " ('PIEDRAS ALBAS', 'female'),\n",
       " ('ALPHA AMADOU', 'male'),\n",
       " ('JUDITH PINO', 'female'),\n",
       " ('LEONIDAS', 'female'),\n",
       " ('ENHUI', 'female'),\n",
       " ('VICTOR MARCOS', 'male'),\n",
       " ('HAMADI', 'male'),\n",
       " ('DIEGO EMANUEL', 'male'),\n",
       " ('MARIA BERNARDA', 'female'),\n",
       " ('HELEN MARIA', 'female'),\n",
       " ('ARIE', 'male'),\n",
       " ('VICTOR FABIAN', 'male'),\n",
       " ('MARIA SALUD', 'female'),\n",
       " ('RONAL', 'male'),\n",
       " ('MARIA BRAULIA', 'female'),\n",
       " ('DILBAG', 'male'),\n",
       " ('PAULA BEATRIZ', 'female'),\n",
       " ('SABIR', 'male'),\n",
       " ('JOSEP', 'male'),\n",
       " ('YEMIMA', 'female'),\n",
       " ('HOSEIN', 'male'),\n",
       " ('CECILIA ANDREA', 'female'),\n",
       " ('GONZALO NAHUEL', 'male'),\n",
       " ('KLEVER ANTONIO', 'male'),\n",
       " ('CONCEPCION LUISA', 'female'),\n",
       " ('JENNIFER JANE', 'female'),\n",
       " ('ALEXANDRU SEBASTIAN', 'male'),\n",
       " ('ANGEL EMILIO', 'male'),\n",
       " ('AMPARO FRANCISCA', 'female'),\n",
       " ('MIREL', 'male'),\n",
       " ('ARIDANE', 'male'),\n",
       " ('VICENTE ARTURO', 'male'),\n",
       " ('LAIE', 'female'),\n",
       " ('IKERNE', 'female'),\n",
       " ('MIHAELA VIORICA', 'female'),\n",
       " ('INGRID LORENA', 'female'),\n",
       " ('ARELIS MARIA', 'female'),\n",
       " ('VITALIJS', 'male'),\n",
       " ('NICOLAS JOSE', 'male'),\n",
       " ('CARLOS IVAN', 'male'),\n",
       " ('IULIANA MARIANA', 'female'),\n",
       " ('HIPOLITA', 'female'),\n",
       " ('GABRIELA ROCIO', 'female'),\n",
       " ('IRENEO', 'male'),\n",
       " ('MARIA JANE', 'female'),\n",
       " ('PIEDAD', 'female'),\n",
       " ('ZORAN', 'male'),\n",
       " ('BOUBEKER', 'male'),\n",
       " ('AIDA CRISTINA', 'female'),\n",
       " ('MIGUEL FEDERICO', 'male'),\n",
       " ('ANTONI LLUIS', 'male'),\n",
       " ('KLAUS', 'male'),\n",
       " ('JULIAN GREGORIO', 'male'),\n",
       " ('SARA JULIANA', 'female'),\n",
       " ('PRAXEDES', 'female'),\n",
       " ('PEILI', 'female'),\n",
       " ('ABDESLAM', 'male'),\n",
       " ('NIKOLAY IVANOV', 'male'),\n",
       " ('LUCIANO DANIEL', 'male'),\n",
       " ('SUSANA ELIZABETH', 'female'),\n",
       " ('SILVESTRE JOSE', 'male'),\n",
       " ('CRISTIAN MIHAI', 'male'),\n",
       " ('ROSENDO JESUS', 'male'),\n",
       " ('EZTIZEN', 'female'),\n",
       " ('CRISTOFFER', 'male'),\n",
       " ('MARIO JOSE', 'male'),\n",
       " ('MARIA ESTELITA', 'female'),\n",
       " ('QUICO', 'male'),\n",
       " ('SONIA RUTH', 'female'),\n",
       " ('JEAN NOEL', 'male'),\n",
       " ('YOANKA', 'female'),\n",
       " ('REMIGIJUS', 'male'),\n",
       " ('ARIELA', 'female'),\n",
       " ('AGUEDA TERESA', 'female'),\n",
       " ('NEREIDA MARIA', 'female'),\n",
       " ('ALVARA', 'female'),\n",
       " ('JOSE DIDIER', 'male'),\n",
       " ('KORAIMA', 'female'),\n",
       " ('DIGNA ROSA', 'female'),\n",
       " ('MARIA SIMONA', 'female'),\n",
       " ('SAUL DAVID', 'male'),\n",
       " ('SERGIO RICARDO', 'male'),\n",
       " ('ANA MARIA CONSUELO', 'female'),\n",
       " ('PATRICIO IVAN', 'male'),\n",
       " ('ALDA MARIA', 'female'),\n",
       " ('NASHIRA', 'female'),\n",
       " ('LUCIA ROCIO', 'female'),\n",
       " ('EVA MAR', 'female'),\n",
       " ('NOELIA ELIZABETH', 'female'),\n",
       " ('ROBERT ANTONIO', 'male'),\n",
       " ('ENZO JOSE', 'male'),\n",
       " ('CARMEN JUANA', 'female'),\n",
       " ('GEORGES', 'male'),\n",
       " ('ALEJANDRO MOISES', 'male'),\n",
       " ('BRYAN PAUL', 'male'),\n",
       " ('ANGELES ROCIO', 'female'),\n",
       " ('SNEHA', 'female'),\n",
       " ('IRINEO', 'male'),\n",
       " ('MONDAY', 'male'),\n",
       " ('NOURREDDINE', 'male'),\n",
       " ('ODIN', 'male'),\n",
       " ('LIBARDO', 'male'),\n",
       " ('FAUSTO ANDRES', 'male'),\n",
       " ('MARTA CONSUELO', 'female'),\n",
       " ('GEORGI STEFANOV', 'male'),\n",
       " ('KAREN LISSETH', 'female'),\n",
       " ('ORLANDO JOSE', 'male'),\n",
       " ('DULCE NOMBRE', 'female'),\n",
       " ('IRIA CARMEN', 'female'),\n",
       " ('BETZABE', 'female'),\n",
       " ('ADOLFO JUAN', 'male'),\n",
       " ('ALEXANDRU CRISTIAN', 'male'),\n",
       " ('DANIEL MAURICIO', 'male'),\n",
       " ('JUAN ROMAN', 'male'),\n",
       " ('NATI', 'female'),\n",
       " ('RADU BOGDAN', 'male'),\n",
       " ('ALEX ALFREDO', 'male'),\n",
       " ('MARLENNY', 'female'),\n",
       " ('HAROLD DAVID', 'male'),\n",
       " ('DANUTA', 'female'),\n",
       " ('RAFAEL SALVADOR', 'male'),\n",
       " ('OLIVIA MARIA', 'female'),\n",
       " ('ANDERSON JOEL', 'male'),\n",
       " ('ADRIAN RAZVAN', 'male'),\n",
       " ('MIHAEL', 'male'),\n",
       " ('SANDRA ASUNCION', 'female'),\n",
       " ...]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.shuffle(tagsetE)\n",
    "tagsetE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'primera_letra': 'd',\n",
       " 'ultima_letra': 'l',\n",
       " 'palabras': 2,\n",
       " 'primera_letra(0)': 'd',\n",
       " 'ultima_letra(0)': 'a',\n",
       " 'primera_letra(1)': 'm',\n",
       " 'ultima_letra(1)': 'l'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atributos_esp('DIANA MARISOL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'primera_letra': 'v',\n",
       " 'ultima_letra': 'a',\n",
       " 'palabras': 1,\n",
       " 'primera_letra(0)': 'v',\n",
       " 'ultima_letra(0)': 'a'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atributos_esp('VASILKA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KuY1Ux30F9uZ"
   },
   "source": [
    "2. **Entrenamiento y performance del modelo**: usando el classificador de Naive Bayes de NLTK entrena un modelo sencillo usando el mismo feature de la última letra del nombre, prueba algunas predicciones y calcula el performance del modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "CvHwHTS8GT9I"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39340\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# escribe tu código aquí\n",
    "fsetE1 = [(atributos(n), g) for (n, g) in tagsetE]\n",
    "trainE1, testE1 = fsetE1[10000:], fsetE1[:10000]\n",
    "print(len(trainE1))\n",
    "print(len(testE1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7894001016776817\n",
      "0.7899\n"
     ]
    }
   ],
   "source": [
    "classifierE1 = nltk.NaiveBayesClassifier.train(trainE1)\n",
    "print(nltk.classify.accuracy(classifierE1, trainE1))\n",
    "print(nltk.classify.accuracy(classifierE1, testE1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "fsetE2 = [(mas_atributos(n), g) for (n, g) in tagsetE]\n",
    "trainE2, testE2 = fsetE2[10000:], fsetE2[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7991103202846975\n",
      "0.8047\n"
     ]
    }
   ],
   "source": [
    "classifierE2 = nltk.NaiveBayesClassifier.train(trainE2)\n",
    "print(nltk.classify.accuracy(classifierE2, trainE2))\n",
    "print(nltk.classify.accuracy(classifierE2, testE2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f4a2jv85GXA_"
   },
   "source": [
    "3. **Mejores atributos:** Define una función como `atributos_esp()` donde puedas extraer mejores atributos con los cuales entrenar una mejor version del clasificador. Haz un segundo entrenamiento y verifica como mejora el performance de tu modelo. ¿Se te ocurren mejores maneras de definir atributos para esta tarea particular?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "9G-E5_CXIQiO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39340\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# escribe tu código aquí\n",
    "fsetE3 = [(atributos_esp(n), g) for (n, g) in tagsetE]\n",
    "trainE3, testE3 = fsetE3[10000:], fsetE3[:10000]\n",
    "print(len(trainE3))\n",
    "print(len(testE3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8632435180477885\n",
      "0.8636\n"
     ]
    }
   ],
   "source": [
    "classifierE3 = nltk.NaiveBayesClassifier.train(trainE3)\n",
    "print(nltk.classify.accuracy(classifierE3, trainE3))\n",
    "print(nltk.classify.accuracy(classifierE3, testE3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K7CXFyfoGf4s"
   },
   "source": [
    "# Clasificación de documentos (email spam o no spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 32
    },
    "id": "Qfli08sgIzl_",
    "outputId": "7b634f01-0956-4843-8eb3-a4e5d2c77d3d",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: la ruta de destino 'datasets' ya existe y no es un directorio vacío.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/pachocamacho1990/datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 115
    },
    "id": "bHFKXxclJ5LC",
    "outputId": "e2878b62-45ed-482a-faa2-92ce90b87731",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oem/Desarrollo/estudio/Escuela de Data Science/clasificacion-con-NLTK/venv/lib/python3.7/site-packages/pandas/compat/__init__.py:117: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n",
      "[nltk_data] Downloading package punkt to /home/oem/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/oem/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 201
    },
    "id": "33oKcvcjKrlM",
    "outputId": "6183550d-66c9-41a4-e2a6-52c9da7ec461",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clase</th>\n",
       "      <th>contenido</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>&lt;!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.0 Tr...</td>\n",
       "      <td>[&lt;, !, DOCTYPE, HTML, PUBLIC, ``, -//W3C//DTD,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>&gt; Russell Turpin:\\n&gt; &gt; That depends on how the...</td>\n",
       "      <td>[&gt;, Russell, Turpin, :, &gt;, &gt;, That, depends, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>Help wanted.  We are a 14 year old fortune 500...</td>\n",
       "      <td>[Help, wanted, ., We, are, a, 14, year, old, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "      <td>Request A Free No Obligation Consultation!\\nAc...</td>\n",
       "      <td>[Request, A, Free, No, Obligation, Consultatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Is there a way to look for a particular file o...</td>\n",
       "      <td>[Is, there, a, way, to, look, for, a, particul...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   clase                                          contenido  \\\n",
       "0     -1  <!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.0 Tr...   \n",
       "1      1  > Russell Turpin:\\n> > That depends on how the...   \n",
       "2     -1  Help wanted.  We are a 14 year old fortune 500...   \n",
       "3     -1  Request A Free No Obligation Consultation!\\nAc...   \n",
       "4      1  Is there a way to look for a particular file o...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [<, !, DOCTYPE, HTML, PUBLIC, ``, -//W3C//DTD,...  \n",
       "1  [>, Russell, Turpin, :, >, >, That, depends, o...  \n",
       "2  [Help, wanted, ., We, are, a, 14, year, old, f...  \n",
       "3  [Request, A, Free, No, Obligation, Consultatio...  \n",
       "4  [Is, there, a, way, to, look, for, a, particul...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('datasets/email/csv/spam-apache.csv', names = ['clase','contenido'])\n",
    "df['tokens'] = df['contenido'].apply(lambda x: word_tokenize(x))\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "OvHkYDylNMKP",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<',\n",
       " '!',\n",
       " 'DOCTYPE',\n",
       " 'HTML',\n",
       " 'PUBLIC',\n",
       " '``',\n",
       " '-//W3C//DTD',\n",
       " 'HTML',\n",
       " '4.0',\n",
       " 'Transitional//EN',\n",
       " \"''\",\n",
       " '>',\n",
       " '<',\n",
       " 'HTML',\n",
       " '>',\n",
       " '<',\n",
       " 'HEAD',\n",
       " '>',\n",
       " '<',\n",
       " 'META',\n",
       " 'http-equiv=Content-Type',\n",
       " 'content=',\n",
       " \"''\",\n",
       " 'text/html',\n",
       " ';',\n",
       " 'charset=iso-8859-1',\n",
       " \"''\",\n",
       " '>',\n",
       " '<',\n",
       " 'META',\n",
       " 'content=',\n",
       " \"''\",\n",
       " 'MSHTML',\n",
       " '6.00.2600.0',\n",
       " \"''\",\n",
       " 'name=GENERATOR',\n",
       " '>',\n",
       " '<',\n",
       " 'STYLE',\n",
       " '>',\n",
       " '<',\n",
       " '/STYLE',\n",
       " '>',\n",
       " '<',\n",
       " '/HEAD',\n",
       " '>',\n",
       " '<',\n",
       " 'BODY',\n",
       " 'bgColor=',\n",
       " '#',\n",
       " 'ffffff',\n",
       " '>',\n",
       " '<',\n",
       " 'DIV',\n",
       " '>',\n",
       " '<',\n",
       " 'FONT',\n",
       " 'face=Arial',\n",
       " 'size=2',\n",
       " '>',\n",
       " '<',\n",
       " 'FONT',\n",
       " 'face=',\n",
       " \"''\",\n",
       " 'Times',\n",
       " 'New',\n",
       " 'Roman',\n",
       " \"''\",\n",
       " 'size=3',\n",
       " '>',\n",
       " 'Dear',\n",
       " 'Friend',\n",
       " ',',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " 'A',\n",
       " 'recent',\n",
       " 'survey',\n",
       " 'by',\n",
       " 'Nielsen/Netratings',\n",
       " 'says',\n",
       " 'that',\n",
       " '``',\n",
       " 'The',\n",
       " 'Internet',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " 'population',\n",
       " 'is',\n",
       " 'rapidly',\n",
       " 'approaching',\n",
       " 'a',\n",
       " \"'Half\",\n",
       " 'a',\n",
       " 'Billion',\n",
       " \"'\",\n",
       " 'people',\n",
       " '!',\n",
       " '``',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " 'SO',\n",
       " 'WHAT',\n",
       " 'DOES',\n",
       " 'ALL',\n",
       " 'THIS',\n",
       " 'MEAN',\n",
       " 'TO',\n",
       " 'YOU',\n",
       " '?',\n",
       " 'EASY',\n",
       " 'MONEY',\n",
       " '!',\n",
       " '!',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " 'Let',\n",
       " \"'s\",\n",
       " 'assume',\n",
       " 'that',\n",
       " 'every',\n",
       " 'person',\n",
       " 'has',\n",
       " 'only',\n",
       " 'one',\n",
       " 'E-mail',\n",
       " 'address',\n",
       " '...',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " 'that',\n",
       " \"'s\",\n",
       " '500',\n",
       " 'million',\n",
       " 'potential',\n",
       " 'customers',\n",
       " 'and',\n",
       " 'growing',\n",
       " '!',\n",
       " 'In',\n",
       " 'addition',\n",
       " ',',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " \"E'mail\",\n",
       " 'is',\n",
       " 'without',\n",
       " 'question',\n",
       " 'the',\n",
       " 'most',\n",
       " 'powerful',\n",
       " 'method',\n",
       " 'of',\n",
       " 'distributing',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " 'information',\n",
       " 'on',\n",
       " 'the',\n",
       " 'face',\n",
       " 'of',\n",
       " 'the',\n",
       " 'earth.',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " 'Well',\n",
       " ',',\n",
       " 'I',\n",
       " 'think',\n",
       " 'you',\n",
       " 'get',\n",
       " 'the',\n",
       " 'picture',\n",
       " '.',\n",
       " 'The',\n",
       " 'numbers',\n",
       " 'and',\n",
       " 'potential',\n",
       " 'are',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " 'just',\n",
       " 'staggering',\n",
       " ',',\n",
       " 'but',\n",
       " 'it',\n",
       " 'gets',\n",
       " 'even',\n",
       " 'better',\n",
       " '...',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " 'Suppose',\n",
       " 'I',\n",
       " 'told',\n",
       " 'you',\n",
       " 'that',\n",
       " 'you',\n",
       " 'could',\n",
       " 'start',\n",
       " 'your',\n",
       " 'own',\n",
       " 'E-mail',\n",
       " 'business',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " 'today',\n",
       " 'and',\n",
       " 'enjoy',\n",
       " 'these',\n",
       " 'benefits',\n",
       " ':',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " '***',\n",
       " 'All',\n",
       " 'Customers',\n",
       " 'Pay',\n",
       " 'You',\n",
       " 'In',\n",
       " 'Cash',\n",
       " '!',\n",
       " '!',\n",
       " '!',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " '***',\n",
       " 'You',\n",
       " 'Will',\n",
       " 'Sell',\n",
       " 'A',\n",
       " 'Product',\n",
       " 'Which',\n",
       " 'Costs',\n",
       " 'Nothing',\n",
       " 'to',\n",
       " 'Produce',\n",
       " '!',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " '***',\n",
       " 'Your',\n",
       " 'Only',\n",
       " 'Overhead',\n",
       " 'Is',\n",
       " 'Your',\n",
       " 'Time',\n",
       " '!',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " '***',\n",
       " 'You',\n",
       " 'Have',\n",
       " '100s',\n",
       " 'Of',\n",
       " 'Millions',\n",
       " 'Of',\n",
       " 'Potential',\n",
       " 'Customers',\n",
       " '!',\n",
       " '!',\n",
       " '!',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " '***',\n",
       " 'You',\n",
       " 'Get',\n",
       " 'Detailed',\n",
       " ',',\n",
       " 'Easy',\n",
       " 'To',\n",
       " 'Follow',\n",
       " 'Startup',\n",
       " 'Instructions',\n",
       " '!',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " 'AND',\n",
       " 'THIS',\n",
       " 'IS',\n",
       " 'JUST',\n",
       " 'THE',\n",
       " 'TIP',\n",
       " 'OF',\n",
       " 'THE',\n",
       " 'ICEBERG',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " 'As',\n",
       " 'you',\n",
       " 'read',\n",
       " 'on',\n",
       " 'you',\n",
       " \"'ll\",\n",
       " 'discover',\n",
       " 'how',\n",
       " 'a',\n",
       " \"'Seen\",\n",
       " 'on',\n",
       " 'National',\n",
       " 'TV',\n",
       " \"'\",\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " 'program',\n",
       " 'is',\n",
       " 'paying',\n",
       " 'out',\n",
       " 'a',\n",
       " 'half',\n",
       " 'million',\n",
       " 'dollars',\n",
       " ',',\n",
       " 'every',\n",
       " '4',\n",
       " 'to',\n",
       " '5',\n",
       " 'months',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " 'from',\n",
       " 'your',\n",
       " 'home',\n",
       " ',',\n",
       " 'for',\n",
       " 'an',\n",
       " 'investment',\n",
       " 'of',\n",
       " 'only',\n",
       " '$',\n",
       " '25',\n",
       " 'US',\n",
       " 'Dollars',\n",
       " 'expense',\n",
       " ',',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " 'one',\n",
       " 'time',\n",
       " '.',\n",
       " 'ALL',\n",
       " 'THANKS',\n",
       " 'TO',\n",
       " 'THE',\n",
       " 'COMPUTER',\n",
       " 'AGE',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " 'AND',\n",
       " 'THE',\n",
       " 'INTERNET',\n",
       " '!',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " 'Before',\n",
       " 'you',\n",
       " 'say',\n",
       " '``',\n",
       " 'Bull',\n",
       " \"''\",\n",
       " ',',\n",
       " 'please',\n",
       " 'read',\n",
       " 'the',\n",
       " 'following',\n",
       " ':',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " 'This',\n",
       " 'is',\n",
       " 'the',\n",
       " 'letter',\n",
       " 'you',\n",
       " 'have',\n",
       " 'been',\n",
       " 'hearing',\n",
       " 'about',\n",
       " 'on',\n",
       " 'the',\n",
       " 'news',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " 'lately',\n",
       " '.',\n",
       " 'Due',\n",
       " 'to',\n",
       " 'the',\n",
       " 'popularity',\n",
       " 'of',\n",
       " 'this',\n",
       " 'letter',\n",
       " 'on',\n",
       " 'the',\n",
       " 'Internet',\n",
       " ',',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " 'a',\n",
       " 'national',\n",
       " 'weekly',\n",
       " 'news',\n",
       " 'program',\n",
       " 'recently',\n",
       " 'devoted',\n",
       " 'an',\n",
       " 'entire',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " 'show',\n",
       " 'to',\n",
       " 'the',\n",
       " 'investigation',\n",
       " 'of',\n",
       " 'this',\n",
       " 'program',\n",
       " 'described',\n",
       " 'below',\n",
       " ',',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " 'to',\n",
       " 'see',\n",
       " 'if',\n",
       " 'it',\n",
       " 'really',\n",
       " 'can',\n",
       " 'make',\n",
       " 'people',\n",
       " 'money.',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " 'The',\n",
       " 'show',\n",
       " 'also',\n",
       " 'investigated',\n",
       " 'whether',\n",
       " 'or',\n",
       " 'not',\n",
       " 'the',\n",
       " 'program',\n",
       " 'was',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " 'legal',\n",
       " '.',\n",
       " 'Their',\n",
       " 'findings',\n",
       " 'proved',\n",
       " 'once',\n",
       " 'and',\n",
       " 'for',\n",
       " 'all',\n",
       " 'that',\n",
       " 'there',\n",
       " 'are',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " \"''\",\n",
       " 'absolutely',\n",
       " 'NO',\n",
       " 'laws',\n",
       " 'prohibiting',\n",
       " 'the',\n",
       " 'participation',\n",
       " 'in',\n",
       " 'the',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " 'program',\n",
       " 'and',\n",
       " 'if',\n",
       " 'people',\n",
       " 'can',\n",
       " 'follow',\n",
       " 'the',\n",
       " 'simple',\n",
       " 'instructions',\n",
       " ',',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " 'they',\n",
       " 'are',\n",
       " 'bound',\n",
       " 'to',\n",
       " 'make',\n",
       " 'some',\n",
       " 'mega',\n",
       " 'bucks',\n",
       " 'with',\n",
       " 'only',\n",
       " '$',\n",
       " '25',\n",
       " 'out',\n",
       " 'of',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " 'pocket',\n",
       " 'cost',\n",
       " \"''\",\n",
       " '.',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " 'DUE',\n",
       " 'TO',\n",
       " 'THE',\n",
       " 'RECENT',\n",
       " 'INCREASE',\n",
       " 'OF',\n",
       " 'POPULARITY',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " 'AND',\n",
       " 'RESPECT',\n",
       " 'THIS',\n",
       " 'PROGRAM',\n",
       " 'HAS',\n",
       " 'ATTAINED',\n",
       " ',',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " 'IT',\n",
       " 'IS',\n",
       " 'CURRENTLY',\n",
       " 'WORKING',\n",
       " 'BETTER',\n",
       " 'THAN',\n",
       " 'EVER',\n",
       " '!',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " '*****',\n",
       " 'This',\n",
       " 'is',\n",
       " 'what',\n",
       " 'one',\n",
       " 'had',\n",
       " 'to',\n",
       " 'say',\n",
       " ':',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " \"''\",\n",
       " 'Thanks',\n",
       " 'to',\n",
       " 'this',\n",
       " 'profitable',\n",
       " 'opportunity',\n",
       " '.',\n",
       " 'I',\n",
       " 'was',\n",
       " 'approached',\n",
       " 'many',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " 'times',\n",
       " 'before',\n",
       " 'but',\n",
       " 'each',\n",
       " 'time',\n",
       " 'I',\n",
       " 'passed',\n",
       " 'on',\n",
       " 'it',\n",
       " '.',\n",
       " 'I',\n",
       " 'am',\n",
       " 'so',\n",
       " 'glad',\n",
       " 'I',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " 'finally',\n",
       " 'joined',\n",
       " 'just',\n",
       " 'to',\n",
       " 'see',\n",
       " 'what',\n",
       " 'one',\n",
       " 'could',\n",
       " 'expect',\n",
       " 'in',\n",
       " 'return',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " 'for',\n",
       " 'the',\n",
       " 'minimal',\n",
       " 'effort',\n",
       " 'and',\n",
       " 'money',\n",
       " 'required',\n",
       " '.',\n",
       " 'To',\n",
       " 'my',\n",
       " 'asonishment',\n",
       " ',',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " 'I',\n",
       " 'received',\n",
       " 'total',\n",
       " '$',\n",
       " '610,470.00',\n",
       " 'in',\n",
       " '21',\n",
       " 'weeks',\n",
       " ',',\n",
       " 'with',\n",
       " 'money',\n",
       " 'still',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " 'coming',\n",
       " 'in',\n",
       " \"''\",\n",
       " '.',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " 'Pam',\n",
       " 'Hedland',\n",
       " ',',\n",
       " 'Fort',\n",
       " 'Lee',\n",
       " ',',\n",
       " 'New',\n",
       " 'Jersey',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " 'Here',\n",
       " 'is',\n",
       " 'another',\n",
       " 'testimonial',\n",
       " ':',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " \"''\",\n",
       " 'This',\n",
       " 'program',\n",
       " 'has',\n",
       " 'been',\n",
       " 'around',\n",
       " 'for',\n",
       " 'a',\n",
       " 'long',\n",
       " 'time',\n",
       " 'but',\n",
       " 'I',\n",
       " 'never',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " 'believed',\n",
       " 'in',\n",
       " 'it',\n",
       " '.',\n",
       " 'But',\n",
       " 'one',\n",
       " 'day',\n",
       " 'when',\n",
       " 'I',\n",
       " 'received',\n",
       " 'this',\n",
       " 'again',\n",
       " 'in',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " 'the',\n",
       " 'mail',\n",
       " 'I',\n",
       " 'decided',\n",
       " 'to',\n",
       " 'gamble',\n",
       " 'my',\n",
       " '$',\n",
       " '25',\n",
       " 'on',\n",
       " 'it',\n",
       " '.',\n",
       " 'I',\n",
       " 'followed',\n",
       " 'the',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " 'simple',\n",
       " 'instructions',\n",
       " 'and',\n",
       " 'walaa',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " '3',\n",
       " 'weeks',\n",
       " 'later',\n",
       " 'the',\n",
       " 'money',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " 'started',\n",
       " 'to',\n",
       " 'come',\n",
       " 'in',\n",
       " '.',\n",
       " 'First',\n",
       " 'month',\n",
       " 'I',\n",
       " 'only',\n",
       " 'made',\n",
       " '$',\n",
       " '240.00',\n",
       " 'but',\n",
       " 'the',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " 'next',\n",
       " '2',\n",
       " 'months',\n",
       " 'after',\n",
       " 'that',\n",
       " 'I',\n",
       " 'made',\n",
       " 'a',\n",
       " 'total',\n",
       " 'of',\n",
       " '$',\n",
       " '290,000.00.',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " 'So',\n",
       " 'far',\n",
       " ',',\n",
       " 'in',\n",
       " 'the',\n",
       " 'past',\n",
       " '8',\n",
       " 'months',\n",
       " 'by',\n",
       " 're-entering',\n",
       " 'the',\n",
       " 'program',\n",
       " ',',\n",
       " 'I',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " 'have',\n",
       " 'made',\n",
       " 'over',\n",
       " '$',\n",
       " '710,000.00',\n",
       " 'and',\n",
       " 'I',\n",
       " 'am',\n",
       " 'playing',\n",
       " 'it',\n",
       " 'again.',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " 'The',\n",
       " 'key',\n",
       " 'to',\n",
       " 'success',\n",
       " 'in',\n",
       " 'this',\n",
       " 'program',\n",
       " 'is',\n",
       " 'to',\n",
       " 'follow',\n",
       " 'the',\n",
       " 'simple',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " 'steps',\n",
       " 'and',\n",
       " 'NOT',\n",
       " 'change',\n",
       " 'anything',\n",
       " '.',\n",
       " '``',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " 'More',\n",
       " 'testimonials',\n",
       " 'later',\n",
       " 'but',\n",
       " 'first',\n",
       " ':',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " '**',\n",
       " 'PRINT',\n",
       " 'THIS',\n",
       " 'NOW',\n",
       " 'FOR',\n",
       " 'YOUR',\n",
       " 'FUTURE',\n",
       " 'REFERENCE',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " 'If',\n",
       " 'you',\n",
       " 'would',\n",
       " 'like',\n",
       " 'to',\n",
       " 'make',\n",
       " 'at',\n",
       " 'least',\n",
       " '$',\n",
       " '500,000',\n",
       " 'every',\n",
       " '4',\n",
       " 'to',\n",
       " '5',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " 'months',\n",
       " 'easily',\n",
       " 'and',\n",
       " 'comfortably',\n",
       " ',',\n",
       " 'please',\n",
       " 'read',\n",
       " 'the',\n",
       " 'following',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " 'THEN',\n",
       " 'READ',\n",
       " 'IT',\n",
       " 'AGAIN',\n",
       " 'and',\n",
       " 'AGAIN',\n",
       " '!',\n",
       " '!',\n",
       " '!',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " '<',\n",
       " 'BR',\n",
       " '>',\n",
       " '**FOLLOW',\n",
       " 'THESE',\n",
       " ...]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokens'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "O4kw1BQUOe4-",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 2200),\n",
       " (',', 2173),\n",
       " ('the', 1963),\n",
       " ('>', 1787),\n",
       " ('--', 1611),\n",
       " ('to', 1435),\n",
       " (':', 1220),\n",
       " ('and', 1064),\n",
       " ('of', 958),\n",
       " ('a', 879),\n",
       " ('you', 743),\n",
       " ('in', 742),\n",
       " ('I', 741),\n",
       " ('<', 718),\n",
       " ('!', 698),\n",
       " ('%', 677),\n",
       " ('for', 609),\n",
       " ('is', 577),\n",
       " ('#', 521),\n",
       " ('BR', 494),\n",
       " ('that', 477),\n",
       " (')', 463),\n",
       " ('it', 458),\n",
       " (\"''\", 434),\n",
       " ('$', 413),\n",
       " ('this', 384),\n",
       " ('(', 380),\n",
       " ('on', 378),\n",
       " ('http', 362),\n",
       " ('?', 360),\n",
       " ('your', 359),\n",
       " ('have', 351),\n",
       " ('with', 334),\n",
       " ('...', 327),\n",
       " ('``', 307),\n",
       " ('be', 299),\n",
       " ('-', 289),\n",
       " ('from', 271),\n",
       " (\"'s\", 263),\n",
       " ('are', 257),\n",
       " ('31', 255),\n",
       " ('or', 252),\n",
       " ('as', 251),\n",
       " ('will', 243),\n",
       " ('not', 224),\n",
       " ('30', 220),\n",
       " ('my', 206),\n",
       " ('at', 199),\n",
       " ('The', 196),\n",
       " ('has', 195),\n",
       " ('can', 194),\n",
       " ('&', 181),\n",
       " ('all', 176),\n",
       " (\"n't\", 175),\n",
       " ('do', 167),\n",
       " ('out', 166),\n",
       " ('but', 164),\n",
       " ('our', 160),\n",
       " ('by', 156),\n",
       " ('if', 152),\n",
       " ('was', 149),\n",
       " ('one', 129),\n",
       " ('an', 129),\n",
       " ('just', 128),\n",
       " ('@', 128),\n",
       " ('This', 125),\n",
       " ('1', 123),\n",
       " ('more', 118),\n",
       " ('You', 117),\n",
       " ('5', 116),\n",
       " ('If', 116),\n",
       " ('we', 116),\n",
       " ('time', 114),\n",
       " ('people', 110),\n",
       " ('me', 110),\n",
       " ('We', 109),\n",
       " ('THE', 108),\n",
       " ('up', 108),\n",
       " ('get', 107),\n",
       " ('they', 103),\n",
       " ('only', 100),\n",
       " ('like', 100),\n",
       " ('so', 99),\n",
       " (\"'\", 95),\n",
       " ('To', 95),\n",
       " ('list', 95),\n",
       " ('2', 94),\n",
       " ('other', 92),\n",
       " ('A', 91),\n",
       " ('would', 88),\n",
       " ('No', 88),\n",
       " ('been', 87),\n",
       " ('any', 87),\n",
       " ('who', 87),\n",
       " ('FREE', 87),\n",
       " ('there', 86),\n",
       " ('which', 86),\n",
       " ('|', 84),\n",
       " ('about', 81),\n",
       " (']', 81),\n",
       " ('some', 80),\n",
       " ('email', 80),\n",
       " ('what', 79),\n",
       " ('AND', 77),\n",
       " ('their', 76),\n",
       " ('TO', 75),\n",
       " ('no', 75),\n",
       " ('then', 74),\n",
       " ('his', 74),\n",
       " ('It', 74),\n",
       " ('address', 73),\n",
       " ('use', 73),\n",
       " ('YOU', 72),\n",
       " ('money', 72),\n",
       " ('3', 72),\n",
       " ('[', 71),\n",
       " ('each', 70),\n",
       " ('work', 70),\n",
       " ('over', 69),\n",
       " ('he', 69),\n",
       " ('make', 68),\n",
       " ('send', 68),\n",
       " ('them', 68),\n",
       " ('OF', 67),\n",
       " ('name', 67),\n",
       " ('than', 67),\n",
       " ('2002', 67),\n",
       " ('could', 66),\n",
       " ('am', 66),\n",
       " ('unseen', 65),\n",
       " ('see', 63),\n",
       " ('YOUR', 63),\n",
       " ('4', 61),\n",
       " ('how', 60),\n",
       " ('way', 60),\n",
       " ('msgs', 59),\n",
       " ('lists/l-k', 59),\n",
       " ('wrote', 58),\n",
       " ('also', 57),\n",
       " ('here', 57),\n",
       " ('Your', 56),\n",
       " ('mail', 56),\n",
       " ('receive', 56),\n",
       " ('go', 56),\n",
       " ('program', 55),\n",
       " ('On', 55),\n",
       " ('new', 55),\n",
       " ('had', 54),\n",
       " ('NOT', 54),\n",
       " ('does', 54),\n",
       " ('want', 54),\n",
       " ('please', 53),\n",
       " ('us', 53),\n",
       " ('because', 53),\n",
       " ('REPORT', 52),\n",
       " ('below', 51),\n",
       " ('when', 51),\n",
       " ('e-mail', 51),\n",
       " (\"'m\", 51),\n",
       " ('free', 50),\n",
       " ('think', 49),\n",
       " ('now', 49),\n",
       " ('first', 48),\n",
       " ('most', 47),\n",
       " ('within', 47),\n",
       " ('Please', 47),\n",
       " ('even', 46),\n",
       " ('using', 46),\n",
       " ('e-mails', 45),\n",
       " ('sent', 45),\n",
       " ('THIS', 44),\n",
       " ('In', 44),\n",
       " ('received', 44),\n",
       " ('company', 44),\n",
       " ('need', 43),\n",
       " ('much', 43),\n",
       " ('*', 43),\n",
       " ('nbsp=3B', 43),\n",
       " ('did', 42),\n",
       " ('And', 42),\n",
       " ('still', 41),\n",
       " ('FOR', 41),\n",
       " (\"'re\", 41),\n",
       " ('know', 41),\n",
       " (';', 40),\n",
       " ('=', 40),\n",
       " ('days', 40),\n",
       " ('where', 40),\n",
       " ('//www.adclick.ws/p.cfm', 40),\n",
       " ('line', 40),\n",
       " ('information', 39),\n",
       " ('US', 39),\n",
       " ('through', 39),\n",
       " ('message', 39),\n",
       " ('Linux', 39),\n",
       " (\"'ve\", 39),\n",
       " ('made', 38),\n",
       " ('different', 38),\n",
       " ('those', 38),\n",
       " ('Report', 38)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words = nltk.FreqDist([w for tokenlist in df['tokens'].values for w in tokenlist])\n",
    "top_words = all_words.most_common(200)\n",
    "top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_features(document, top_words=top_words):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word, freq in top_words:\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "1g6F_qNfmRAW",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'contains(.)': True,\n",
       " 'contains(,)': True,\n",
       " 'contains(the)': True,\n",
       " 'contains(>)': True,\n",
       " 'contains(--)': True,\n",
       " 'contains(to)': True,\n",
       " 'contains(:)': True,\n",
       " 'contains(and)': True,\n",
       " 'contains(of)': True,\n",
       " 'contains(a)': True,\n",
       " 'contains(you)': True,\n",
       " 'contains(in)': True,\n",
       " 'contains(I)': True,\n",
       " 'contains(<)': True,\n",
       " 'contains(!)': True,\n",
       " 'contains(%)': True,\n",
       " 'contains(for)': True,\n",
       " 'contains(is)': True,\n",
       " 'contains(#)': True,\n",
       " 'contains(BR)': True,\n",
       " 'contains(that)': True,\n",
       " 'contains())': True,\n",
       " 'contains(it)': True,\n",
       " \"contains('')\": True,\n",
       " 'contains($)': True,\n",
       " 'contains(this)': True,\n",
       " 'contains(()': True,\n",
       " 'contains(on)': True,\n",
       " 'contains(http)': False,\n",
       " 'contains(?)': True,\n",
       " 'contains(your)': True,\n",
       " 'contains(have)': True,\n",
       " 'contains(with)': True,\n",
       " 'contains(...)': True,\n",
       " 'contains(``)': True,\n",
       " 'contains(be)': True,\n",
       " 'contains(-)': True,\n",
       " 'contains(from)': True,\n",
       " \"contains('s)\": True,\n",
       " 'contains(are)': True,\n",
       " 'contains(31)': False,\n",
       " 'contains(or)': True,\n",
       " 'contains(as)': True,\n",
       " 'contains(will)': True,\n",
       " 'contains(not)': True,\n",
       " 'contains(30)': False,\n",
       " 'contains(my)': True,\n",
       " 'contains(at)': True,\n",
       " 'contains(The)': True,\n",
       " 'contains(has)': True,\n",
       " 'contains(can)': True,\n",
       " 'contains(&)': True,\n",
       " 'contains(all)': True,\n",
       " \"contains(n't)\": False,\n",
       " 'contains(do)': True,\n",
       " 'contains(out)': True,\n",
       " 'contains(but)': True,\n",
       " 'contains(our)': False,\n",
       " 'contains(by)': True,\n",
       " 'contains(if)': True,\n",
       " 'contains(was)': True,\n",
       " 'contains(one)': True,\n",
       " 'contains(an)': True,\n",
       " 'contains(just)': True,\n",
       " 'contains(@)': False,\n",
       " 'contains(This)': True,\n",
       " 'contains(1)': True,\n",
       " 'contains(more)': True,\n",
       " 'contains(You)': True,\n",
       " 'contains(5)': True,\n",
       " 'contains(If)': True,\n",
       " 'contains(we)': True,\n",
       " 'contains(time)': True,\n",
       " 'contains(people)': True,\n",
       " 'contains(me)': True,\n",
       " 'contains(We)': True,\n",
       " 'contains(THE)': True,\n",
       " 'contains(up)': False,\n",
       " 'contains(get)': True,\n",
       " 'contains(they)': True,\n",
       " 'contains(only)': True,\n",
       " 'contains(like)': True,\n",
       " 'contains(so)': True,\n",
       " \"contains(')\": True,\n",
       " 'contains(To)': True,\n",
       " 'contains(list)': True,\n",
       " 'contains(2)': True,\n",
       " 'contains(other)': True,\n",
       " 'contains(A)': True,\n",
       " 'contains(would)': True,\n",
       " 'contains(No)': False,\n",
       " 'contains(been)': True,\n",
       " 'contains(any)': True,\n",
       " 'contains(who)': True,\n",
       " 'contains(FREE)': True,\n",
       " 'contains(there)': True,\n",
       " 'contains(which)': False,\n",
       " 'contains(|)': False,\n",
       " 'contains(about)': True,\n",
       " 'contains(])': False,\n",
       " 'contains(some)': True,\n",
       " 'contains(email)': True,\n",
       " 'contains(what)': True,\n",
       " 'contains(AND)': True,\n",
       " 'contains(their)': True,\n",
       " 'contains(TO)': True,\n",
       " 'contains(no)': True,\n",
       " 'contains(then)': True,\n",
       " 'contains(his)': False,\n",
       " 'contains(It)': False,\n",
       " 'contains(address)': True,\n",
       " 'contains(use)': False,\n",
       " 'contains(YOU)': True,\n",
       " 'contains(money)': True,\n",
       " 'contains(3)': True,\n",
       " 'contains([)': False,\n",
       " 'contains(each)': True,\n",
       " 'contains(work)': True,\n",
       " 'contains(over)': True,\n",
       " 'contains(he)': False,\n",
       " 'contains(make)': True,\n",
       " 'contains(send)': True,\n",
       " 'contains(them)': True,\n",
       " 'contains(OF)': True,\n",
       " 'contains(name)': True,\n",
       " 'contains(than)': True,\n",
       " 'contains(2002)': False,\n",
       " 'contains(could)': True,\n",
       " 'contains(am)': True,\n",
       " 'contains(unseen)': False,\n",
       " 'contains(see)': True,\n",
       " 'contains(YOUR)': True,\n",
       " 'contains(4)': True,\n",
       " 'contains(how)': True,\n",
       " 'contains(way)': True,\n",
       " 'contains(msgs)': False,\n",
       " 'contains(lists/l-k)': False,\n",
       " 'contains(wrote)': False,\n",
       " 'contains(also)': True,\n",
       " 'contains(here)': False,\n",
       " 'contains(Your)': True,\n",
       " 'contains(mail)': True,\n",
       " 'contains(receive)': True,\n",
       " 'contains(go)': True,\n",
       " 'contains(program)': True,\n",
       " 'contains(On)': True,\n",
       " 'contains(new)': False,\n",
       " 'contains(had)': True,\n",
       " 'contains(NOT)': True,\n",
       " 'contains(does)': True,\n",
       " 'contains(want)': False,\n",
       " 'contains(please)': True,\n",
       " 'contains(us)': True,\n",
       " 'contains(because)': True,\n",
       " 'contains(REPORT)': True,\n",
       " 'contains(below)': True,\n",
       " 'contains(when)': True,\n",
       " 'contains(e-mail)': True,\n",
       " \"contains('m)\": False,\n",
       " 'contains(free)': True,\n",
       " 'contains(think)': True,\n",
       " 'contains(now)': False,\n",
       " 'contains(first)': True,\n",
       " 'contains(most)': True,\n",
       " 'contains(within)': False,\n",
       " 'contains(Please)': False,\n",
       " 'contains(even)': True,\n",
       " 'contains(using)': False,\n",
       " 'contains(e-mails)': True,\n",
       " 'contains(sent)': True,\n",
       " 'contains(THIS)': True,\n",
       " 'contains(In)': True,\n",
       " 'contains(received)': True,\n",
       " 'contains(company)': False,\n",
       " 'contains(need)': True,\n",
       " 'contains(much)': True,\n",
       " 'contains(*)': False,\n",
       " 'contains(nbsp=3B)': False,\n",
       " 'contains(did)': False,\n",
       " 'contains(And)': False,\n",
       " 'contains(still)': True,\n",
       " 'contains(FOR)': True,\n",
       " \"contains('re)\": False,\n",
       " 'contains(know)': False,\n",
       " 'contains(;)': True,\n",
       " 'contains(=)': True,\n",
       " 'contains(days)': True,\n",
       " 'contains(where)': False,\n",
       " 'contains(//www.adclick.ws/p.cfm)': False,\n",
       " 'contains(line)': False,\n",
       " 'contains(information)': True,\n",
       " 'contains(US)': True,\n",
       " 'contains(through)': True,\n",
       " 'contains(message)': False,\n",
       " 'contains(Linux)': False,\n",
       " \"contains('ve)\": False,\n",
       " 'contains(made)': True,\n",
       " 'contains(different)': True,\n",
       " 'contains(those)': True,\n",
       " 'contains(Report)': True}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_features(df['tokens'].values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K7CXFyfoGf4s"
   },
   "source": [
    "Lo primero que hacemos es un conjunto de atributos como una lista de **tuplas**, obteniendo **textos** y **clases**. De esta forma estamos recorriendo dos listas de forma simultanea.\n",
    "\n",
    "La función `zip` se utiliza porque se estan recorriendo dos listas de forma simultanea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "SrCXXGMCn3zz",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "fset = [(document_features(texto), clase) for texto, clase in zip(df['tokens'].values, df['clase'].values)]\n",
    "random.shuffle(fset)\n",
    "train, test = fset[:200], fset[200:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "r6FGZE4OqkEa",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.97\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier, train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 32
    },
    "id": "xIyVc6lBrGOy",
    "outputId": "01479a1e-6f68-4423-d4d3-6b1f9673f43c",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.94\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier, test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 214
    },
    "id": "wKzgha92up3l",
    "outputId": "ec079b59-5973-4084-e6ab-2f66037e92e5",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      <!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.0 Tr...\n",
       "2      Help wanted.  We are a 14 year old fortune 500...\n",
       "3      Request A Free No Obligation Consultation!\\nAc...\n",
       "10     >\\n>“µ×è¹µÑÇ ¡ÑºâÅ¡¸ØÃ¡Ô¨º¹ÍÔ¹àµÍÃìà¹çµ” \\n>àµ...\n",
       "11     ==============================================...\n",
       "                             ...                        \n",
       "243    ##############################################...\n",
       "244    Wanna see sexually curious teens playing with ...\n",
       "246    REQUEST FOR URGENT BUSINESS ASSISTANCE\\n------...\n",
       "248    Email marketing works!  There's no way around ...\n",
       "249    Email marketing works!  There's no way around ...\n",
       "Name: contenido, Length: 125, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['clase']==-1]['contenido']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 115
    },
    "id": "1x-R_PImrKIV",
    "outputId": "3b384c67-1640-422f-d9a1-19e41b42c667",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "             contains(]) = True                1 : -1     =     13.3 : 1.0\n",
      "          contains(YOUR) = True               -1 : 1      =     12.1 : 1.0\n",
      "            contains(We) = True               -1 : 1      =     11.9 : 1.0\n",
      "             contains([) = True                1 : -1     =     11.9 : 1.0\n",
      "         contains(below) = True               -1 : 1      =     10.0 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YeBvifrnr3GY"
   },
   "source": [
    "## Ejercicio de práctica\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AR53vedlvd1O"
   },
   "source": [
    "¿Como podrías construir un mejor clasificador de documentos?\n",
    "\n",
    "0. **Dataset más grande:** El conjunto de datos que usamos fue muy pequeño, considera usar los archivos corpus que estan ubicados en la ruta: `datasets/email/plaintext/` \n",
    "\n",
    "1. **Limpieza:** como te diste cuenta no hicimos ningun tipo de limpieza de texto en los correos electrónicos. Considera usar expresiones regulares, filtros por categorias gramaticales, etc ... . \n",
    "\n",
    "---\n",
    "\n",
    "Con base en eso construye un dataset más grande y con un tokenizado más pulido. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "TOw2KrtnymVT",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Descomprimir ZIP\n",
    "import zipfile\n",
    "fantasy_zip = zipfile.ZipFile('datasets/email/plaintext/corpus1.zip')\n",
    "fantasy_zip.extractall('datasets/email/plaintext')\n",
    "fantasy_zip.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "v2ZO0aJyrTLx",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Creamos un listado de los archivos dentro del Corpus1 ham/spam\n",
    "from os import listdir\n",
    "\n",
    "path_ham = \"datasets/email/plaintext/corpus1/ham/\"\n",
    "filepaths_ham = [path_ham+f for f in listdir(path_ham) if f.endswith('.txt')]\n",
    "\n",
    "path_spam = \"datasets/email/plaintext/corpus1/spam/\"\n",
    "filepaths_spam = [path_spam+f for f in listdir(path_spam) if f.endswith('.txt')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Creamos la funcion para tokenizar y leer los archivos \n",
    "\n",
    "def abrir(texto):\n",
    "    with open(texto, 'r', errors='ignore') as f2:\n",
    "        data = f2.read()\n",
    "        data = word_tokenize(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos la lista tokenizada del ham\n",
    "list_ham = list(map(abrir, filepaths_ham))\n",
    "# Creamos la lista tokenizada del spam\n",
    "list_spam = list(map(abrir, filepaths_spam))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9V_KmDBHwiy8"
   },
   "source": [
    "2. **Validación del modelo anterior:**  \n",
    "---\n",
    "\n",
    "una vez tengas el nuevo conjunto de datos más pulido y de mayor tamaño, considera el mismo entrenamiento con el mismo tipo de atributos del ejemplo anterior, ¿mejora el accuracy del modelo resultante?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2lC72_CbxAoJ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "3. **Construye mejores atributos**: A veces no solo se trata de las palabras más frecuentes sino de el contexto, y capturar contexto no es posible solo viendo los tokens de forma individual, ¿que tal si consideramos bi-gramas, tri-gramas ...?, ¿las secuencias de palabras podrián funcionar como mejores atributos para el modelo?. Para ver si es así,  podemos extraer n-gramas de nuestro corpus y obtener sus frecuencias de aparición con `FreqDist()`, desarrolla tu propia manera de hacerlo y entrena un modelo con esos nuevos atributos, no olvides compartir tus resultados en la sección de comentarios. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Separamos las palabras mas comunes\n",
    "all_words = nltk.FreqDist([w for tokenlist in list_ham+list_spam for w in tokenlist])\n",
    "top_words = all_words.most_common(250)\n",
    "top_words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Agregamos Bigramas\n",
    "bigram_text = nltk.Text([w for token in list_ham+list_spam for w in token])\n",
    "bigrams = list(nltk.bigrams(bigram_text))\n",
    "top_bigrams = (nltk.FreqDist(bigrams)).most_common(250)\n",
    "top_bigrams"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def document_featuresEmail(document, top_words=top_words, top_bigrams=top_bigrams):\n",
    "    document_words = set(document)\n",
    "    bigram = set(list(nltk.bigrams(nltk.Text([token for token in document]))))\n",
    "    features = {}\n",
    "    for word, j in top_words:\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "\n",
    "    for bigrams, i in top_bigrams:\n",
    "        features['contains_bigram({})'.format(bigrams)] = (bigrams in bigram)\n",
    "  \n",
    "    return features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Juntamos las listas indicando si tienen palabras de las mas comunes\n",
    "import random\n",
    "fset_ham = [(document_features(texto), 0) for texto in list_ham]\n",
    "fset_spam = [(document_features(texto), 1) for texto in list_spam]\n",
    "fset = fset_spam + fset_ham\n",
    "random.shuffle(fset)\n",
    "len(fset)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fset_train, fset_test = fset[:2000], fset[2000:]\n",
    "# Entrenamos el programa\n",
    "classifier = nltk.NaiveBayesClassifier.train(fset_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classifier.classify(document_features(list_ham[34]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(nltk.classify.accuracy(classifier, fset_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classifier.show_most_informative_features(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('-', 85724),\n",
       " ('.', 54709),\n",
       " ('/', 42848),\n",
       " (',', 40664),\n",
       " (':', 30278),\n",
       " ('the', 25656),\n",
       " ('to', 20345),\n",
       " ('ect', 13900),\n",
       " ('and', 12829),\n",
       " ('@', 12736),\n",
       " ('for', 10508),\n",
       " ('of', 10188),\n",
       " ('a', 9820),\n",
       " ('you', 8162),\n",
       " ('in', 7717),\n",
       " (\"'\", 7542),\n",
       " ('on', 7317),\n",
       " ('hou', 7289),\n",
       " ('this', 7171),\n",
       " ('is', 7170),\n",
       " ('?', 6881),\n",
       " ('enron', 6555),\n",
       " ('i', 6391),\n",
       " (')', 6089),\n",
       " ('(', 5758),\n",
       " ('>', 5622),\n",
       " ('Subject', 5172),\n",
       " ('be', 5067),\n",
       " ('=', 4912),\n",
       " ('that', 4769),\n",
       " (';', 4708),\n",
       " ('2000', 4386),\n",
       " ('we', 4341),\n",
       " ('from', 4192),\n",
       " ('will', 4137),\n",
       " ('have', 4097),\n",
       " ('your', 4042),\n",
       " ('with', 3987),\n",
       " ('at', 3735),\n",
       " ('com', 3710),\n",
       " ('!', 3637),\n",
       " ('s', 3435),\n",
       " ('are', 3388),\n",
       " ('it', 3335),\n",
       " ('please', 3200),\n",
       " ('as', 3157),\n",
       " ('if', 3135),\n",
       " ('or', 3080),\n",
       " ('not', 3074),\n",
       " ('gas', 3034),\n",
       " ('``', 3020),\n",
       " ('_', 3009),\n",
       " ('by', 3000),\n",
       " ('3', 2922),\n",
       " ('$', 2891),\n",
       " ('subject', 2889),\n",
       " ('deal', 2827),\n",
       " ('1', 2743),\n",
       " ('me', 2572),\n",
       " ('am', 2533),\n",
       " ('meter', 2459),\n",
       " ('00', 2404),\n",
       " ('#', 2385),\n",
       " ('2', 2379),\n",
       " ('cc', 2371),\n",
       " ('pm', 2343),\n",
       " ('hpl', 2318),\n",
       " ('can', 2143),\n",
       " ('d', 2134),\n",
       " ('000', 2127),\n",
       " ('10', 2113),\n",
       " ('our', 2092),\n",
       " ('2001', 2028),\n",
       " ('any', 2000),\n",
       " ('re', 1984),\n",
       " ('e', 1976),\n",
       " ('all', 1929),\n",
       " ('daren', 1901),\n",
       " ('thanks', 1898),\n",
       " ('01', 1794),\n",
       " ('corp', 1776),\n",
       " ('|', 1739),\n",
       " ('was', 1687),\n",
       " ('has', 1653),\n",
       " ('%', 1609),\n",
       " ('&', 1604),\n",
       " ('know', 1588),\n",
       " ('0', 1586),\n",
       " ('4', 1577),\n",
       " ('*', 1574),\n",
       " ('5', 1565),\n",
       " ('an', 1511),\n",
       " ('need', 1480),\n",
       " ('11', 1440),\n",
       " ('new', 1437),\n",
       " ('t', 1403),\n",
       " ('may', 1383),\n",
       " ('no', 1380),\n",
       " ('up', 1357),\n",
       " ('mmbtu', 1349),\n",
       " ('12', 1345),\n",
       " ('do', 1338),\n",
       " ('j', 1336),\n",
       " ('should', 1308),\n",
       " ('forwarded', 1297),\n",
       " ('get', 1276),\n",
       " ('there', 1236),\n",
       " ('http', 1235),\n",
       " ('03', 1222),\n",
       " ('price', 1206),\n",
       " ('see', 1200),\n",
       " ('company', 1198),\n",
       " ('these', 1186),\n",
       " ('let', 1160),\n",
       " ('out', 1157),\n",
       " ('information', 1154),\n",
       " ('farmer', 1141),\n",
       " ('been', 1115),\n",
       " ('l', 1108),\n",
       " ('attached', 1097),\n",
       " ('7', 1092),\n",
       " ('but', 1083),\n",
       " ('would', 1078),\n",
       " ('99', 1068),\n",
       " ('so', 1050),\n",
       " ('6', 1043),\n",
       " ('02', 1040),\n",
       " ('m', 1036),\n",
       " ('xls', 1020),\n",
       " ('us', 1018),\n",
       " ('they', 1018),\n",
       " ('what', 1010),\n",
       " ('day', 1007),\n",
       " ('time', 994),\n",
       " ('my', 993),\n",
       " ('into', 981),\n",
       " ('message', 966),\n",
       " ('only', 951),\n",
       " ('9', 949),\n",
       " ('here', 945),\n",
       " ('more', 942),\n",
       " ('04', 939),\n",
       " ('one', 935),\n",
       " ('30', 935),\n",
       " ('contract', 920),\n",
       " ('20', 918),\n",
       " ('th', 906),\n",
       " ('volume', 900),\n",
       " ('8', 894),\n",
       " ('mail', 892),\n",
       " ('robert', 886),\n",
       " ('05', 884),\n",
       " ('month', 878),\n",
       " ('sitara', 861),\n",
       " ('09', 860),\n",
       " ('about', 848),\n",
       " ('p', 848),\n",
       " ('which', 843),\n",
       " ('08', 836),\n",
       " ('email', 833),\n",
       " ('nom', 832),\n",
       " ('texas', 827),\n",
       " ('deals', 808),\n",
       " ('energy', 805),\n",
       " ('their', 796),\n",
       " ('volumes', 790),\n",
       " ('questions', 787),\n",
       " ('now', 783),\n",
       " ('15', 783),\n",
       " ('sent', 775),\n",
       " ('also', 764),\n",
       " ('+', 760),\n",
       " ('just', 758),\n",
       " ('www', 756),\n",
       " ('pec', 752),\n",
       " ('change', 735),\n",
       " ('ena', 732),\n",
       " ('some', 721),\n",
       " ('when', 712),\n",
       " ('bob', 710),\n",
       " ('production', 703),\n",
       " ('flow', 697),\n",
       " ('x', 697),\n",
       " ('call', 694),\n",
       " ('file', 684),\n",
       " ('other', 676),\n",
       " ('b', 664),\n",
       " ('like', 661),\n",
       " ('net', 659),\n",
       " ('25', 652),\n",
       " ('following', 651),\n",
       " ('06', 647),\n",
       " ('c', 633),\n",
       " ('31', 624),\n",
       " ('07', 621),\n",
       " ('over', 620),\n",
       " ('21', 611),\n",
       " ('report', 604),\n",
       " ('contact', 602),\n",
       " ('o', 599),\n",
       " ('back', 599),\n",
       " ('want', 597),\n",
       " ('nomination', 585),\n",
       " ('them', 580),\n",
       " ('he', 579),\n",
       " ('daily', 578),\n",
       " ('per', 578),\n",
       " ('could', 577),\n",
       " ('ticket', 577),\n",
       " ('16', 572),\n",
       " ('below', 570),\n",
       " ('24', 568),\n",
       " ('gary', 564),\n",
       " ('make', 562),\n",
       " ('713', 560),\n",
       " ('mary', 558),\n",
       " ('original', 556),\n",
       " ('were', 550),\n",
       " ('list', 547),\n",
       " ('march', 546),\n",
       " ('business', 546),\n",
       " ('days', 542),\n",
       " (']', 539),\n",
       " ('[', 536),\n",
       " ('number', 534),\n",
       " ('july', 529),\n",
       " ('april', 528),\n",
       " ('who', 528),\n",
       " ('its', 527),\n",
       " ('don', 526),\n",
       " ('first', 522),\n",
       " ('100', 522),\n",
       " ('through', 519),\n",
       " ('system', 518),\n",
       " ('inc', 517),\n",
       " ('font', 517),\n",
       " ('today', 516),\n",
       " ('sale', 516),\n",
       " ('14', 516),\n",
       " ('free', 515),\n",
       " ('r', 512),\n",
       " ('effective', 508),\n",
       " ('forward', 507),\n",
       " ('order', 504),\n",
       " ('td', 504),\n",
       " ('28', 501),\n",
       " ('how', 498),\n",
       " ('statements', 498),\n",
       " ('plant', 488),\n",
       " ('well', 488)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('-', '-'), 65612),\n",
       " (('/', 'ect'), 7313),\n",
       " (('/', 'hou'), 7278),\n",
       " (('hou', '/'), 7278),\n",
       " (('@', 'ect'), 6547),\n",
       " (('ect', '@'), 6420),\n",
       " (('Subject', ':'), 5172),\n",
       " (('.', '.'), 4350),\n",
       " (('ect', ','), 4278),\n",
       " (('>', '>'), 3810),\n",
       " (('.', 'com'), 3650),\n",
       " (('?', '?'), 3213),\n",
       " (('to', ':'), 2766),\n",
       " (('/', '2000'), 2700),\n",
       " (('subject', ':'), 2683),\n",
       " (('@', 'enron'), 2524),\n",
       " (('/', 'enron'), 2409),\n",
       " ((\"'\", 's'), 2380),\n",
       " (('cc', ':'), 2336),\n",
       " (('of', 'the'), 2317),\n",
       " (('.', 'i'), 1877),\n",
       " (('.', 'the'), 1840),\n",
       " (('=', '='), 1786),\n",
       " (('in', 'the'), 1748),\n",
       " (('re', ':'), 1646),\n",
       " (('enron', '@'), 1629),\n",
       " ((':', 're'), 1613),\n",
       " (('if', 'you'), 1587),\n",
       " (('_', '_'), 1558),\n",
       " (('for', 'the'), 1545),\n",
       " ((',', '000'), 1446),\n",
       " (('ect', 'cc'), 1388),\n",
       " (('will', 'be'), 1378),\n",
       " (('on', 'the'), 1367),\n",
       " (('pm', 'to'), 1351),\n",
       " (('.', 'thanks'), 1318),\n",
       " ((',', 'and'), 1294),\n",
       " ((':', '/'), 1271),\n",
       " (('/', '/'), 1267),\n",
       " (('from', ':'), 1260),\n",
       " (('-', 'forwarded'), 1249),\n",
       " (('forwarded', 'by'), 1248),\n",
       " (('to', 'the'), 1225),\n",
       " (('http', ':'), 1223),\n",
       " (('/', 'corp'), 1192),\n",
       " (('corp', '/'), 1191),\n",
       " (('am', 'to'), 1114),\n",
       " ((':', 'subject'), 1097),\n",
       " (('/', '00'), 1063),\n",
       " (('.', 'please'), 1062),\n",
       " (('to', 'be'), 1051),\n",
       " ((\"'\", 't'), 1043),\n",
       " ((\"'\", ';'), 1029),\n",
       " (('you', 'have'), 1028),\n",
       " ((';', \"'\"), 1025),\n",
       " (('.', 'xls'), 1020),\n",
       " (('.', 'Subject'), 992),\n",
       " (('enron', ','), 977),\n",
       " (('.', 'this'), 957),\n",
       " ((',', 'i'), 956),\n",
       " (('daren', 'j'), 923),\n",
       " (('.', 'if'), 923),\n",
       " (('.', 'we'), 908),\n",
       " (('let', 'me'), 905),\n",
       " (('enron', '.'), 902),\n",
       " (('/', '2001'), 897),\n",
       " ((',', 'the'), 886),\n",
       " (('me', 'know'), 875),\n",
       " (('/', '01'), 870),\n",
       " (('/', 'd'), 862),\n",
       " ((',', 'please'), 858),\n",
       " (('ect', 'on'), 831),\n",
       " (('!', '!'), 806),\n",
       " ((',', '2000'), 799),\n",
       " (('j', 'farmer'), 780),\n",
       " (('is', 'a'), 766),\n",
       " (('need', 'to'), 761),\n",
       " (('com', \"'\"), 760),\n",
       " (('thanks', ','), 754),\n",
       " (('e', '-'), 753),\n",
       " (('www', '.'), 747),\n",
       " (('000', '/'), 738),\n",
       " ((',', '2001'), 735),\n",
       " (('this', 'is'), 730),\n",
       " (('ect', 'subject'), 726),\n",
       " (('with', 'the'), 715),\n",
       " (('mmbtu', '/'), 715),\n",
       " (('03', '/'), 710),\n",
       " (('.', '-'), 710),\n",
       " ((')', '.'), 695),\n",
       " (('pm', '-'), 674),\n",
       " (('*', '*'), 672),\n",
       " (('-', 'from'), 670),\n",
       " (('at', 'the'), 658),\n",
       " (('.', '000'), 650),\n",
       " (('.', '00'), 643),\n",
       " (('1', '/'), 638),\n",
       " (('should', 'be'), 636),\n",
       " (('10', '/'), 632),\n",
       " ((',', 'we'), 626),\n",
       " (('i', 'have'), 624),\n",
       " (('-', 'mail'), 617),\n",
       " (('com', '/'), 609),\n",
       " (('/', '99'), 608),\n",
       " (('am', '-'), 606),\n",
       " (('10', ':'), 592),\n",
       " (('farmer', '/'), 583),\n",
       " (('the', 'following'), 583),\n",
       " ((':', '00'), 581),\n",
       " (('i', \"'\"), 580),\n",
       " (('11', '/'), 579),\n",
       " (('is', 'the'), 575),\n",
       " (('have', 'any'), 569),\n",
       " (('/', 'hpl'), 560),\n",
       " ((')', '-'), 556),\n",
       " (('it', 'is'), 549),\n",
       " (('/', 'www'), 549),\n",
       " ((',', 'but'), 546),\n",
       " (('i', 'will'), 544),\n",
       " (('you', 'can'), 543),\n",
       " (('com', ','), 541),\n",
       " (('of', 'this'), 537),\n",
       " (('05', '/'), 536),\n",
       " (('12', '/'), 532),\n",
       " (('any', 'questions'), 526),\n",
       " (('and', 'the'), 526),\n",
       " (('i', 'am'), 519),\n",
       " (('01', '/'), 517),\n",
       " (('1', '.'), 514),\n",
       " (('.', 'net'), 513),\n",
       " (('see', 'attached'), 510),\n",
       " (('we', 'have'), 509),\n",
       " (('|', '|'), 499),\n",
       " (('don', \"'\"), 497),\n",
       " (('.', 'it'), 496),\n",
       " (('attached', 'file'), 495),\n",
       " (('message', '-'), 490),\n",
       " (('04', '/'), 490),\n",
       " (('we', 'are'), 486),\n",
       " (('xls', 'Subject'), 482),\n",
       " (('06', '/'), 482),\n",
       " (('0', '.'), 480),\n",
       " (('corp', '.'), 475),\n",
       " (('(', 'see'), 474),\n",
       " (('file', ':'), 472),\n",
       " (('the', 'deal'), 466),\n",
       " (('meter', '#'), 464),\n",
       " (('=', '3'), 464),\n",
       " (('2', '/'), 460),\n",
       " (('please', 'let'), 458),\n",
       " (('3', '/'), 456),\n",
       " (('02', '/'), 454),\n",
       " (('know', 'if'), 448),\n",
       " (('original', 'message'), 446),\n",
       " (('3', '-'), 445),\n",
       " (('has', 'been'), 445),\n",
       " (('-', 'original'), 444),\n",
       " (('.', 'you'), 442),\n",
       " (('sent', ':'), 441),\n",
       " (('11', ':'), 441),\n",
       " (('from', 'the'), 435),\n",
       " (('2', '.'), 432),\n",
       " ((':', 'hpl'), 426),\n",
       " (('fw', ':'), 426),\n",
       " ((':', 'fw'), 425),\n",
       " (('inc', '.'), 424),\n",
       " (('000', 'mmbtu'), 423),\n",
       " ((',', 'or'), 423),\n",
       " ((':', 'meter'), 419),\n",
       " (('xls', ')'), 416),\n",
       " (('have', 'been'), 416),\n",
       " (('.', 'in'), 412),\n",
       " (('deal', '#'), 410),\n",
       " (('there', 'is'), 408),\n",
       " (('the', 'company'), 405),\n",
       " (('/', 'pec'), 395),\n",
       " (('03', ':'), 394),\n",
       " (('s', '.'), 393),\n",
       " (('have', 'a'), 392),\n",
       " (('07', '/'), 390),\n",
       " (('to', 'get'), 390),\n",
       " (('08', '/'), 390),\n",
       " (('02', ':'), 387),\n",
       " (('you', 'are'), 383),\n",
       " (('that', 'the'), 383),\n",
       " (('thank', 'you'), 380),\n",
       " (('1', ','), 379),\n",
       " ((':', 'daren'), 379),\n",
       " ((',', 'daren'), 378),\n",
       " (('nbsp', ';'), 378),\n",
       " (('is', 'not'), 375),\n",
       " (('.', 'from'), 369),\n",
       " (('713', '-'), 368),\n",
       " ((':', 'robert'), 367),\n",
       " ((':', 'http'), 366),\n",
       " (('not', 'be'), 364),\n",
       " (('the', 'gas'), 363),\n",
       " (('daren', ','), 360),\n",
       " (('pec', '@'), 357),\n",
       " (('@', 'pec'), 357),\n",
       " (('2000', '10'), 356),\n",
       " (('09', ':'), 353),\n",
       " (('for', 'your'), 353),\n",
       " (('$', '0'), 353),\n",
       " (('/', '1'), 348),\n",
       " (('want', 'to'), 348),\n",
       " (('we', 'will'), 347),\n",
       " (('.', '('), 346),\n",
       " (('thanks', '.'), 345),\n",
       " (('that', 'we'), 338),\n",
       " (('enron', 'on'), 337),\n",
       " (('4', '/'), 336),\n",
       " (('6', '/'), 336),\n",
       " (('a', '.'), 335),\n",
       " (('do', 'not'), 334),\n",
       " (('teco', 'tap'), 333),\n",
       " (('=', 'http'), 333),\n",
       " (('09', '/'), 332),\n",
       " (('.', '0'), 330),\n",
       " (('me', '.'), 329),\n",
       " ((':', '$'), 329),\n",
       " (('08', ':'), 327),\n",
       " (('north', 'america'), 325),\n",
       " (('for', 'a'), 325),\n",
       " (('3', '.'), 322),\n",
       " ((',', 'inc'), 322),\n",
       " (('.', '99'), 322),\n",
       " (('01', ':'), 320),\n",
       " (('the', 'month'), 318),\n",
       " ((\"'\", 'll'), 317),\n",
       " (('04', ':'), 315),\n",
       " (('by', 'the'), 315),\n",
       " (('enron', 'cc'), 312),\n",
       " (('12', ':'), 312),\n",
       " (('pec', ','), 310),\n",
       " ((')', ','), 309),\n",
       " (('set', 'up'), 308),\n",
       " (('/', '31'), 305),\n",
       " (('to', 'you'), 305),\n",
       " (('gas', 'daily'), 304),\n",
       " (('width', '='), 304),\n",
       " (('based', 'on'), 303),\n",
       " (('tenaska', 'iv'), 299),\n",
       " ((',', 'you'), 299),\n",
       " (('.', 'for'), 296),\n",
       " (('height', '='), 296),\n",
       " (('you', 'will'), 295),\n",
       " ((',', 'melissa'), 293),\n",
       " (('on', 'this'), 292),\n",
       " ((\"'\", 'm'), 291)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agregamos Bigramas\n",
    "bigram_text = nltk.Text([w for token in list_ham+list_spam for w in token])\n",
    "bigrams = list(nltk.bigrams(bigram_text))\n",
    "top_bigrams = (nltk.FreqDist(bigrams)).most_common(250)\n",
    "top_bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "AM6Vhy-Fw8oj",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def document_featuresEmail(document, top_words=top_words, top_bigrams=top_bigrams):\n",
    "    document_words = set(document)\n",
    "    bigram = set(list(nltk.bigrams(nltk.Text([token for token in document]))))\n",
    "    features = {}\n",
    "    for word, j in top_words:\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "\n",
    "    for bigrams, i in top_bigrams:\n",
    "        features['contains_bigram({})'.format(bigrams)] = (bigrams in bigram)\n",
    "  \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "wtMkQWpfxoy3",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5172"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Juntamos las listas indicando si tienen palabras de las mas comunes\n",
    "import random\n",
    "fset_ham = [(document_features(texto), 0) for texto in list_ham]\n",
    "fset_spam = [(document_features(texto), 1) for texto in list_spam]\n",
    "fset = fset_spam + fset_ham\n",
    "random.shuffle(fset)\n",
    "len(fset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "fset_train, fset_test = fset[:2000], fset[2000:]\n",
    "# Entrenamos el programa\n",
    "classifier = nltk.NaiveBayesClassifier.train(fset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify(document_features(list_ham[34]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9025851197982345\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier, fset_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "             contains(|) = True                1 : 0      =     23.0 : 1.0\n",
      "          contains(http) = True                1 : 0      =      7.7 : 1.0\n",
      "         contains(money) = True                1 : 0      =      7.3 : 1.0\n",
      "            contains(am) = True                0 : 1      =      7.0 : 1.0\n",
      "             contains(*) = True                1 : 0      =      6.4 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "[Lecture_19/20]Modelos_clasificacion.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}