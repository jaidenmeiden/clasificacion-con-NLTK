{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6YTaQq9dCh0E"
   },
   "source": [
    "# Clasificación de palabras (por género de nombre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49
    },
    "id": "5co_TuOhC4ze",
    "outputId": "6ed198ee-9cb9-48b9-ab74-db9655585c0e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package names to /home/oem/nltk_data...\n",
      "[nltk_data]   Package names is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk, random\n",
    "nltk.download('names')\n",
    "from nltk.corpus import names "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ijhsE2PBFYxm"
   },
   "source": [
    "**Función básica de extracción de atributos**\n",
    "\n",
    "Creamos una función donde nos devuelve unicamente la última letra de cada palabra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "b0kKV62lCZ55"
   },
   "outputs": [],
   "source": [
    "# definición de atributos relevantes\n",
    "def atributos(palabra):\n",
    "    return {'Ultima letra': palabra[-1]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ijhsE2PBFYxm"
   },
   "source": [
    "Unimos la lista de nombres **masculinos** y **femeninos** en una lista de tuplas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7944"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagset = [(name, 'male') for name in names.words('male.txt')] + [(name, 'female') for name in names.words('female.txt')]\n",
    "len(tagset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ijhsE2PBFYxm"
   },
   "source": [
    "Hacemos que la lista sea distribuida aleatoriamente para evitar el sesgo, ya que la lista de nombres masculinos queda primero que la lista de nombres femeninos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 181
    },
    "id": "IjfK5ZKwDL__",
    "outputId": "fef1000d-e474-43f0-986d-10b721946e59"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Henry', 'male'),\n",
       " ('Shani', 'female'),\n",
       " ('Ichabod', 'male'),\n",
       " ('Ferdy', 'male'),\n",
       " ('Saxe', 'male'),\n",
       " ('Federico', 'male'),\n",
       " ('Asia', 'female'),\n",
       " ('Coralie', 'female'),\n",
       " ('Bettye', 'female'),\n",
       " ('Giffer', 'male')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.shuffle(tagset)\n",
    "tagset[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ijhsE2PBFYxm"
   },
   "source": [
    "Creo una segunda lista de atributos, ya que nuestro modelo NO lee los nombres, sino los atributos de los nombres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 181
    },
    "id": "jZcAN-dmCrok",
    "outputId": "b114852f-8e71-4121-fda3-21bb731353b4"
   },
   "outputs": [],
   "source": [
    "fset1 = [(atributos(n), g) for (n, g) in tagset]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ijhsE2PBFYxm"
   },
   "source": [
    "Divido el dataset en los conjuntos de entrenamiento y pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "QzK97C8BDmHR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5944\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "train1, test1 = fset1[2000:], fset1[:2000]\n",
    "print(len(train1))\n",
    "print(len(test1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qQPv0tW4Fd2G"
   },
   "source": [
    "**Modelo de clasificación Naive Bayes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "37jueg4nDQFs"
   },
   "outputs": [],
   "source": [
    "# entrenamiento del modelo NaiveBayes\n",
    "classifier = nltk.NaiveBayesClassifier.train(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BAWfUSHrEj3q"
   },
   "source": [
    " **Verificación de algunas predicciones**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "Mr8ytm8SEEZk",
    "outputId": "cf62ff8a-2722-4331-bf70-66aafff1d9e8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'female'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify(atributos('amanda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "c0GG1Y1_EPaO",
    "outputId": "6f286792-7845-44f8-b22b-1cf6815036a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'male'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify(atributos('peter'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XSUK14XhEqLL"
   },
   "source": [
    "**Performance del modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 32
    },
    "id": "p5S9qeCgsJSg",
    "outputId": "6339e65d-d66e-4c96-9053-ea70d0abdea7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7617765814266487\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier, train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 32
    },
    "id": "lenwC5agEdvT",
    "outputId": "1ceb5e52-4db6-4c5f-c714-dbf72f90e652"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.766\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier, test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aSNI7OFxGib0"
   },
   "source": [
    "**Mejores atributos**\n",
    "\n",
    "Los atributos se almacenan en un diccionario. Creo una función de atributos completamente personalizada (Hay que recordar que no hay un protocolo establecido para definir atributos).\n",
    "\n",
    "Para este caso:\n",
    "* Atributo 1: La primera letra de la palabra\n",
    "* Atributo 2: La última letra de la palabra\n",
    "* Atributo 3: Cuantas veces aparece una letra del alfabeto en la palabra\n",
    "* Atributo 4: Si el alfabeto tiene o no tiene una letra del alfabeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "k5uaIAdDGlq8"
   },
   "outputs": [],
   "source": [
    "def mas_atributos(nombre):\n",
    "    atributos = {}\n",
    "    atributos[\"primera_letra\"] = nombre[0].lower()\n",
    "    atributos[\"ultima_letra\"] = nombre[-1].lower()\n",
    "    for letra in 'abcdefghijklmnopqrstuvwxyz':\n",
    "        atributos[\"count({})\".format(letra)] = nombre.lower().count(letra)\n",
    "        atributos[\"has({})\".format(letra)] = (letra in nombre.lower())\n",
    "    return atributos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "6-gJIxKcHKvI"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'primera_letra': 'j',\n",
       " 'ultima_letra': 'n',\n",
       " 'count(a)': 0,\n",
       " 'has(a)': False,\n",
       " 'count(b)': 0,\n",
       " 'has(b)': False,\n",
       " 'count(c)': 0,\n",
       " 'has(c)': False,\n",
       " 'count(d)': 0,\n",
       " 'has(d)': False,\n",
       " 'count(e)': 0,\n",
       " 'has(e)': False,\n",
       " 'count(f)': 0,\n",
       " 'has(f)': False,\n",
       " 'count(g)': 0,\n",
       " 'has(g)': False,\n",
       " 'count(h)': 1,\n",
       " 'has(h)': True,\n",
       " 'count(i)': 0,\n",
       " 'has(i)': False,\n",
       " 'count(j)': 1,\n",
       " 'has(j)': True,\n",
       " 'count(k)': 0,\n",
       " 'has(k)': False,\n",
       " 'count(l)': 0,\n",
       " 'has(l)': False,\n",
       " 'count(m)': 0,\n",
       " 'has(m)': False,\n",
       " 'count(n)': 1,\n",
       " 'has(n)': True,\n",
       " 'count(o)': 1,\n",
       " 'has(o)': True,\n",
       " 'count(p)': 0,\n",
       " 'has(p)': False,\n",
       " 'count(q)': 0,\n",
       " 'has(q)': False,\n",
       " 'count(r)': 0,\n",
       " 'has(r)': False,\n",
       " 'count(s)': 0,\n",
       " 'has(s)': False,\n",
       " 'count(t)': 0,\n",
       " 'has(t)': False,\n",
       " 'count(u)': 0,\n",
       " 'has(u)': False,\n",
       " 'count(v)': 0,\n",
       " 'has(v)': False,\n",
       " 'count(w)': 0,\n",
       " 'has(w)': False,\n",
       " 'count(x)': 0,\n",
       " 'has(x)': False,\n",
       " 'count(y)': 0,\n",
       " 'has(y)': False,\n",
       " 'count(z)': 0,\n",
       " 'has(z)': False}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mas_atributos('jhon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "FBu25HHgHQtK"
   },
   "outputs": [],
   "source": [
    "fset2 = [(mas_atributos(n), g) for (n, g) in tagset]\n",
    "train2, test2 = fset2[2000:], fset2[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier2 = nltk.NaiveBayesClassifier.train(train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(nltk.classify.accuracy(classifier2, train2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(nltk.classify.accuracy(classifier2, test2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7792732166890982\n"
     ]
    }
   ],
   "source": [
    "### Ejercicio de práctica\n",
    "\n",
    "**Objetivo:** Construye un classificador de nombres en español usando el siguiente dataset: \n",
    "https://github.com/jvalhondo/spanish-names-surnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 32
    },
    "id": "8hWR9hOzHlNe",
    "outputId": "97d5f514-dfd5-474a-8755-4127a7bcb8dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.772\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier2, test2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rT7mmVnvFAcm"
   },
   "source": [
    "### Ejercicio de práctica\n",
    "\n",
    "**Objetivo:** Construye un classificador de nombres en español usando el siguiente dataset: \n",
    "https://github.com/jvalhondo/spanish-names-surnames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NphJqahkFnjO"
   },
   "source": [
    "1. **Preparación de los datos**: con un `git clone` puedes traer el dataset indicado a tu directorio en Colab, luego asegurate de darle el formato adecuado a los datos y sus features para que tenga la misma estructura del ejemplo anterior con el dataset `names` de nombres en ingles. \n",
    "\n",
    "* **Piensa y analiza**: ¿los features en ingles aplican de la misma manera para los nombres en español?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "OhbOT6_zFGHM"
   },
   "outputs": [],
   "source": [
    "# escribe tu código aquí\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KuY1Ux30F9uZ"
   },
   "source": [
    "2. **Entrenamiento y performance del modelo**: usando el classificador de Naive Bayes de NLTK entrena un modelo sencillo usando el mismo feature de la última letra del nombre, prueba algunas predicciones y calcula el performance del modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "CvHwHTS8GT9I"
   },
   "outputs": [],
   "source": [
    "# escribe tu código aquí\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f4a2jv85GXA_"
   },
   "source": [
    "3. **Mejores atributos:** Define una función como `atributos2()` donde puedas extraer mejores atributos con los cuales entrenar una mejor version del clasificador. Haz un segundo entrenamiento y verifica como mejora el performance de tu modelo. ¿Se te ocurren mejores maneras de definir atributos para esta tarea particular?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "9G-E5_CXIQiO"
   },
   "outputs": [],
   "source": [
    "# escribe tu código aquí\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K7CXFyfoGf4s"
   },
   "source": [
    "# Clasificación de documentos (email spam o no spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 32
    },
    "id": "Qfli08sgIzl_",
    "outputId": "7b634f01-0956-4843-8eb3-a4e5d2c77d3d",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: la ruta de destino 'datasets' ya existe y no es un directorio vacío.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/pachocamacho1990/datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 115
    },
    "id": "bHFKXxclJ5LC",
    "outputId": "e2878b62-45ed-482a-faa2-92ce90b87731",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oem/Desarrollo/estudio/Escuela de Data Science/clasificacion-con-NLTK/venv/lib/python3.7/site-packages/pandas/compat/__init__.py:117: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n",
      "[nltk_data] Downloading package punkt to /home/oem/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/oem/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 201
    },
    "id": "33oKcvcjKrlM",
    "outputId": "6183550d-66c9-41a4-e2a6-52c9da7ec461",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OvHkYDylNMKP",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O4kw1BQUOe4-",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1g6F_qNfmRAW",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SrCXXGMCn3zz",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r6FGZE4OqkEa",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 32
    },
    "id": "xIyVc6lBrGOy",
    "outputId": "01479a1e-6f68-4423-d4d3-6b1f9673f43c",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 115
    },
    "id": "1x-R_PImrKIV",
    "outputId": "3b384c67-1640-422f-d9a1-19e41b42c667",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 214
    },
    "id": "wKzgha92up3l",
    "outputId": "ec079b59-5973-4084-e6ab-2f66037e92e5",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YeBvifrnr3GY"
   },
   "source": [
    "## Ejercicio de práctica\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AR53vedlvd1O"
   },
   "source": [
    "¿Como podrías construir un mejor clasificador de documentos?\n",
    "\n",
    "0. **Dataset más grande:** El conjunto de datos que usamos fue muy pequeño, considera usar los archivos corpus que estan ubicados en la ruta: `datasets/email/plaintext/` \n",
    "\n",
    "1. **Limpieza:** como te diste cuenta no hicimos ningun tipo de limpieza de texto en los correos electrónicos. Considera usar expresiones regulares, filtros por categorias gramaticales, etc ... . \n",
    "\n",
    "---\n",
    "\n",
    "Con base en eso construye un dataset más grande y con un tokenizado más pulido. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TOw2KrtnymVT",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "v2ZO0aJyrTLx",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# escribe tu código aquí:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9V_KmDBHwiy8"
   },
   "source": [
    "2. **Validación del modelo anterior:**  \n",
    "---\n",
    "\n",
    "una vez tengas el nuevo conjunto de datos más pulido y de mayor tamaño, considera el mismo entrenamiento con el mismo tipo de atributos del ejemplo anterior, ¿mejora el accuracy del modelo resultante?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "AM6Vhy-Fw8oj",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# escribe tu código aquí:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2lC72_CbxAoJ"
   },
   "source": [
    "3. **Construye mejores atributos**: A veces no solo se trata de las palabras más frecuentes sino de el contexto, y capturar contexto no es posible solo viendo los tokens de forma individual, ¿que tal si consideramos bi-gramas, tri-gramas ...?, ¿las secuencias de palabras podrián funcionar como mejores atributos para el modelo?. Para ver si es así,  podemos extraer n-gramas de nuestro corpus y obtener sus frecuencias de aparición con `FreqDist()`, desarrolla tu propia manera de hacerlo y entrena un modelo con esos nuevos atributos, no olvides compartir tus resultados en la sección de comentarios. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "wtMkQWpfxoy3",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# escribe tu código aquí:\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "[Lecture_19/20]Modelos_clasificacion.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}